<!-- 
#################################################
# HEAD - FOR ALL PAGES
#################################################
 --><!doctype html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name="author" content="Martin Alfaro"><script>function applySavedTheme(){"enabled"===localStorage.getItem("darkMode")&&document.documentElement.classList.add("dark-mode")}applySavedTheme()</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Cormorant+SC:wght@300;400;600;700&family=Inter:wght@300..900&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet"><link rel="stylesheet" href="/julia_book/libs/katex/katex.min.css"><link rel="stylesheet" href="/julia_book/libs/highlight/styles/vs_myversion.css"><link rel="stylesheet" href="/julia_book/css/bootstrap.min.css"><style>.section-bg-color{background-color:rgba(63,99,136,.07)}footer a{color:#6495ed}header{margin-top:0!important}header .jumbotron{background-image:linear-gradient(to right,#000,#000 10%,#3f6388 55%,#3f6388);background-repeat:no-repeat;background-size:100%}</style><link rel="stylesheet" href="/julia_book/css/custom.css"><title>11f. Parallelization in Practice - Julia Book - Martin Alfaro</title><link rel="icon" type="image/png" href="/julia_book/assets/icons/favicon.ico"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-K96JNP7PKB"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K96JNP7PKB")</script><body id="page-top"><!-- 
#################################################
# FOR EACH SPECIFIC PAGE
#################################################
 --><style>html{scroll-behavior:auto}.bar_top,.jumbotron,.left_bar,.nav-item,.navbar,footer{font-size:16px;font-family:"Open Sans"}.franklin-content{font-size:17px;font-family:"Open Sans"}h1{font-family:Inter,"Open Sans";font-weight:600}h1{padding-top:.1em;font-size:210%!important;font-weight:700;text-align:center}.phd_format{color:#fff;text-decoration:none;font-size:90%;text-align:center;margin-top:-.2em;margin-bottom:-.89em}.name_format{padding-top:.35em;text-decoration:none;font-size:160%}.name_format a{color:#fff}.name_format a:hover{color:#d4d4d4;color:#d6e3f0}.franklin-content{background-color:#d9e0e7}.franklin-content{margin:0;width:100%;height:100%;justify-content:center;text-align:justify;text-justify:inter-word;line-height:1.65}.jumbotron{margin-bottom:0;padding-top:42px;padding-bottom:2em;border-bottom:#000 solid 1px;border-radius:0}.franklin-content,.jumbotron{padding-left:160px}footer{background-image:linear-gradient(to right,#23374b,#000 50%,#3f6388);background-color:#3f6388;width:calc(100%+10px);margin-left:-10px;padding-left:10px}h2{text-transform:uppercase;font-size:160%;text-align:center;text-decoration:underline;padding-bottom:.5em;font-weight:700}h3{text-align:left;text-transform:uppercase;text-decoration:underline;padding-bottom:0;padding-top:.5em;font-size:120%;font-weight:600}h4 a{font-weight:800!important}h4{text-align:left;color:#3a6c9e;text-decoration:underline;padding-bottom:0;padding-top:.5em;font-weight:800!important;text-transform:uppercase;font-size:120%}h5,h6{text-indent:0;line-height:1.2em;padding-top:.99em;padding-bottom:-0em}section{margin-left:0;padding-left:1%;padding-right:1%;padding-top:1.5%;padding-bottom:1%;text-align:justify;text-justify:inter-word;line-height:1.65;text-indent:0;font-size:100%;color:#000}section h1{text-indent:0;margin-left:0}section h2{text-indent:0;margin-bottom:0}.franklin-content ul{margin-left:0;margin-top:-.6em;line-height:1.15}.franklin-content ul li p{margin-left:0;margin-bottom:.6em;line-height:1.35;text-indent:0}.franklin-content ol li{margin-left:2em;line-height:1.15}ul ::marker{color:#49739d}ol ::marker{color:#5381af;font-weight:700}a.anchor{display:block;position:relative;top:-150px;visibility:hidden}section a{color:#3e79b4;text-decoration:underline;font-weight:500}section a:hover{color:rgba(62,121,180,.699);text-decoration:underline}</style><style>:target{scroll-margin-top:40px}.own-anchors a{scroll-margin-top:4em}</style><div class="left_bar" style="color:#fff"><span><img src="/julia_book/assets/pics_html/julia_logo-dark.svg" alt="pic" style="padding:12px;padding-right:28px;padding-top:44px" width="160px" height="auto"></span><ul><li style="text-transform:uppercase"><a href="/julia_book/index.html"><img src="/julia_book/assets/icons/home.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Home</a></li><li style="text-transform:uppercase"><a href="/julia_book/list_posts/"><img src="/julia_book/assets/icons/books03.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Chapters</a></li><li><div style="text-indent:0"><button class="modalButton" style="text-transform:uppercase"><img src="/julia_book/assets/icons/keyboard01.png" style="width:20%;height:auto;opacity:.9;margin-bottom:-26px;margin-left:-30px;padding-right:4px"> <span style="margin-left:-.2em">Notation &<div style="margin-left:-1.2em;margin-top:-3em">Hotkeys</div></span></button><div class="kbd_shortcuts"><div class="modal" id="kbdmodal_bar"><div class="modal-content"><div class="modal-header"><h2>NOTATION</h2></div><div class="modal-body" style="height:auto">Generic expressions are represented by <b>&lt;something&gt;</b> (e.g., <code>&lt;function&gt;</code> or <code>&lt;operator&gt;</code>). This is just notation, and the symbols <code>&lt;</code> and <code>&gt;</code> should not be misconstrued as Julia's syntax.</div><div class="modal-header"><h2>PAGE LAYOUT</h2></div><div class="modal-body">If you want to adjust the size of the font, <b>zoom in or out on pages</b> by respectively using <kbd>Ctrl</kbd>+<kbd>+</kbd> and <kbd>Ctrl</kbd>+<kbd>-</kbd>. The layout will adjust automatically.<br><span class="brmine"></span></div><div class="modal-header"><h2>LINKS TO SECTIONS</h2></div><div class="modal-body">To quickly share a link to a specific section, simply hover over the title and click on it. The link will be automatically copied to your clipboard, ready to be pasted. <span class="brmine"></span></div><div class="modal-header"><h2>KEYBOARD SHORTCUTS</h2></div><div class="modal-body"><style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:#000;border-style:solid;border-width:1px;overflow:hidden;padding:10px 12px;word-break:normal}.tg th{border-color:#000;border-style:solid;border-width:1px;font-weight:400;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-80zn{background-color:rgba(63,99,136,.2);border-color:#fff;font-weight:700;text-align:center;vertical-align:top}.tg .tg-esg4{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:right;vertical-align:top}.tg .tg-8jgo{border-color:#fff;text-align:left;vertical-align:top}.tg .tg-ofj5{border-color:#fff;text-align:center;vertical-align:top}</style><table class="tg" style="margin-left:auto;margin-right:auto"><thead><tr><th class="tg-80zn">Action</th><th class="tg-80zn">Keyboard Shortcut</th></tr></thead><tbody><tr><td class="tg-8jgo">Previous Section</td><td class="tg-ofj5"><kbd>Ctrl + ðŸ ˜</kbd></td></tr><tr><td class="tg-8jgo">Next Section</td><td class="tg-ofj5"><kbd>Ctrl + ðŸ š</kbd></td></tr><tr><td class="tg-8jgo">List of Sections</td><td class="tg-ofj5"><kbd>Ctrl + z</kbd></td></tr><tr><td class="tg-8jgo">List of Subsections</td><td class="tg-ofj5"><kbd>Ctrl + x</kbd></td></tr><tr><td class="tg-8jgo">Close Any Popped Up Window (like this one)</td><td class="tg-ofj5"><kbd>Esc</kbd></td></tr><tr><td class="tg-8jgo">Open All Codes and Outputs in a Post</td><td class="tg-ofj5"><kbd>Alt + ðŸ ›</kbd></td></tr><tr><td class="tg-8jgo">Close All Codes and Outputs in a Post</td><td class="tg-ofj5"><kbd>Alt + ðŸ ™</kbd></td></tr></tbody></table><span class="brmine"></span></div><div class="modal-header"><h2>TIME MEASUREMENT</h2></div><div class="modal-body">When benchmarking, the equivalence of time measures is as follows.<br><br><style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:#000;border-style:solid;border-width:1px;overflow:hidden;padding:10px 5px;word-break:normal}.tg th{border-color:#000;border-style:solid;border-width:1px;font-weight:400;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-80zn{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:left;vertical-align:top}.tg .tg-esg4{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:right;vertical-align:top}.tg .tg-8jgo{border-color:#fff;text-align:left;vertical-align:top}.tg .tg-ofj5{border-color:#fff;text-align:center;vertical-align:top}</style><table class="tg" style="margin-left:auto;margin-right:auto"><thead><tr><th class="tg-80zn">Unit</th><th class="tg-80zn">Acronym</th><th class="tg-80zn">Measure in Seconds</th></tr></thead><tbody><tr><td class="tg-8jgo">Seconds</td><td class="tg-ofj5">s</td><td class="tg-ofj5">1</td></tr><tr><td class="tg-8jgo">Milliseconds</td><td class="tg-ofj5">ms</td><td class="tg-ofj5">10<sup>-3</sup></td></tr><tr><td class="tg-8jgo">Microseconds</td><td class="tg-ofj5">Î¼s</td><td class="tg-ofj5">10<sup>-6</sup></td></tr><tr><td class="tg-8jgo">Nanoseconds</td><td class="tg-ofj5">ns</td><td class="tg-ofj5">10<sup>-9</sup></td></tr></tbody></table></div></div><style>.left_bar .kbd_shortcuts{color:#000;font-size:16px;line-height:1.55;list-style-type:none;position:relative}.left_bar .kbd_shortcuts kbd{font-size:14px}.left_bar .kbd_shortcuts .modal-content{position:relative;width:1200px;max-width:90%;height:max-content;max-height:90%;margin-top:55px;background-color:#cfdae4;overflow:auto}.left_bar .kbd_shortcuts .modal-body{margin:0;padding-bottom:12px;text-align:justify;padding-top:8px;padding-bottom:2px;overflow:visible;height:100%}.left_bar .kbd_shortcuts .modal-header{padding:0;color:#fff;width:100%}.left_bar .kbd_shortcuts .modal-header h2{padding-top:8px;font-size:20px;font-weight:700;width:100%;text-align:center;color:#fff;background-color:#3f6388}.left_bar .modalButton{border:none;box-shadow:none;width:auto;padding:0;background-color:transparent;color:#fff;margin:0}.left_bar .brmine{display:block;margin-bottom:.5em}</style></div></div></div></li><li style="text-transform:uppercase"><a href="/julia_book/links/"><img src="/julia_book/assets/icons/links.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Links</a></li><li><a href="/julia_book/assets/pdf/juliaBook_Alfaro.pdf"><img src="/julia_book/assets/icons/icon_pdf.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> BOOK in PDF</a></li><li><h3 style="font-weight:400;font-size:14px;padding-top:4em;margin-bottom:-.6em;text-decoration:none">Dark Mode</h3><label class="switch"><input type="checkbox" id="toggleStyles"> <span class="slider round"></span></label></li></ul><div class="searchForm"><form action="https://duckduckgo.com/" method="get" onsubmit="return prependSiteOperator()"><input type="text" id="searchInput" name="q" placeholder="Search..." required></form></div><div class="personal_website"><a href="https://alfaromartino.github.io"><img src="/julia_book/assets/icons/personal.png" style="width:18%;height:auto;opacity:.9;margin-bottom:-14px;padding-right:4px"> Personal<div style="margin-left:calc(30px + 2px);margin-top:-.5em">Website</div></a></div></div><style>@media (max-width:850px),(max-height:600px){.left_bar{display:none}}.left_bar{z-index:200;background-image:linear-gradient(to left bottom,#000,#000 10%,#3f6388 80%,#3f6388);position:fixed;font-family:Inter,"Open Sans";height:100%;top:0;left:0;font-size:20px;width:160px}.left_bar ul{list-style-type:none;float:left;font-size:80%;position:relative;padding-left:.8em;padding-top:40px;line-height:4.25em}.left_bar .personal_website a,.left_bar li a{color:#fff}.left_bar .personal_website a:hover,.left_bar a:hover{color:#a09f9f}.left_bar .personal_website{position:absolute;bottom:0;padding-bottom:1em;left:12px;font-size:20px;font-family:"Cormorant SC";font-weight:700}</style><script>function prependSiteOperator(){var e=document.getElementById("searchInput");return e.value="site:https://alfaromartino.github.io/julia_book/ "+e.value,!0}</script><style>.left_bar .searchForm{width:100%}.left_bar .searchForm input[type=text]{width:100%;box-sizing:border-box;background-color:inherit;border:0 solid;border-color:#fff;height:60px;color:#fff;padding-left:.6em;font-size:85%}</style><style>.switch{position:relative;display:inline-block;width:30px;height:17px}.switch input{display:none}.slider{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#ccc;transition:.4s}.slider:before{position:absolute;content:"";height:13px;width:13px;left:2px;bottom:2px;background-color:#fff;transition:.4s}input:checked+.slider{background-color:#000}input:checked+.slider:before{transform:translateX(13px)}.slider.round{border-radius:17px}.slider.round:before{border-radius:50%}html.dark-mode{background-color:#030911!important}html.dark-mode .franklin-content,html.dark-mode .modal-body{background-color:#030911!important}html.dark-mode .franklin-content section,html.dark-mode .index_container,html.dark-mode .modal-content{color:#ebf4fc!important}html.dark-mode .index_container,html.dark-mode .index_container h1{background-color:#030d18!important}html.dark-mode .index_container ul>li{color:#ebf4fc!important}html.dark-mode .index_container a{color:#588cc0}html.dark-mode .index_container a:hover,html.dark-mode h2:hover,html.dark-mode section a:hover{color:#bed5ec}html.dark-mode .multiple_pics{background-color:#4b6d92}html.dark-mode .multiple_pics h2{color:#fff!important}html.dark-mode .note,html.dark-mode .warning{color:#000}html.dark-mode .code_box,html.dark-mode .code_in_modal,html.dark-mode .img_output_in_modal,html.dark-mode .output_in_modal{border-width:1px;border-style:solid;border-color:rgba(0,44,82,.99)}html.dark-mode .tab_wrapper .tab_code_links .tablink.active{background-color:rgba(94,140,185,.95)}html.dark-mode .tab_wrapper .tab_code_links .tablink:hover{background-color:rgba(94,140,185,.95)}html.dark-mode .bar_top,html.dark-mode .nav-menu.show,html.dark-mode nav .nav-toggle{background-image:linear-gradient(to top,#122030,#122030 60%)!important}html.dark-mode .bar_top .modal-body,html.dark-mode .bar_top .modal-content,html.dark-mode .bar_top .modal-header{background-image:linear-gradient(to top,#122030,#122030 60%)!important}html.dark-mode header .jumbotron{background-image:linear-gradient(to bottom,#122030,#122030 50%)!important}html.dark-mode .left_bar{background-image:linear-gradient(to left bottom,#122030,#122030 10%)}html.dark-mode footer{background-image:linear-gradient(to right,#122030,#000 10%)!important;border-top:1px solid rgba(0,44,82,.99);background-color:rgba(63,99,136,.3);width:calc(100%+10px);margin-left:0;padding-left:10px}html.dark-mode .left_bar .kbd_shortcuts .modal-content{background-color:#000!important}</style><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("toggleStyles"),t=document.documentElement;"enabled"===localStorage.getItem("darkMode")&&(e.checked=!0),e.addEventListener("change",function(){this.checked?(t.classList.add("dark-mode"),localStorage.setItem("darkMode","enabled")):(t.classList.remove("dark-mode"),localStorage.setItem("darkMode","disabled"))})})</script><header class="text-white text-center"><div class="jumbotron jumbotron-fluid container-fluid bg-primary"><h1><i>11f.</i> Parallelization in Practice</h1><div class="lead"></div><div class="name_format"><a href="https://alfaromartino.github.io/" target="_blank" rel="noopener noreferrer">Martin Alfaro</a></div><div class="phd_format">PhD in Economics</div></div></header><link href="https://fonts.cdnfonts.com/css/cascadia-mono" rel="stylesheet"><style>pre{position:relative;overflow:hidden}code{background-color:#d1d9e0;color:#000;text-indent:0;padding-top:.1em;padding-bottom:.1em;padding-left:.3em;padding-right:.3em;vertical-align:.05em;border:1px solid #001029;overflow:hidden}.julia_repl_NoFormat code,.mixed_output_NoFormat code{background-color:#527868;color:#dcdcdc;border:1px solid #527868}.copy-button{cursor:pointer;border:none;font-size:12px;text-transform:lowercase;font-weight:500;padding:2px 10px 2px;background-color:#3f6388;position:absolute;top:0;right:12px;text-align:center;color:#fff;margin-top:0;z-index:1}.copy-button:hover{outline:0;background-color:#5483b3}.copy-button:focus{outline:0;background-color:#324e6b}.julia_line{color:#20c679!important;font-weight:700;display:inline;font-size:100%}.julia_repl_NoFormat{font-size:87%}.julia_repl_NoFormat .julia_line,.julia_repl_NoFormat code{font-size:100%}.mixed_output_NoFormat{font-size:87%}.mixed_output_NoFormat .julia_line,.mixed_output_NoFormat code,.mixed_output_NoFormat pre{font-size:100%}.akin_to_pre{white-space:pre-wrap;font-family:Consolas,monospace}.julia_repl_NoFormat{font-family:Consolas,monospace;color:#dcdcdc;border:none;background-color:#013b1f;margin:0;padding:0}.julia_repl_NoFormat .akin_to_pre{line-height:1.35;color:#dcdcdc;margin:0;padding:0}.franklin_output_NoFormat{font-family:Consolas,monospace;margin:0;padding:0;background-color:#013b1f}.franklin_output_NoFormat pre{margin:0;padding:0;line-height:1.35;background-color:#013b1f}.franklin_output_NoFormat pre code{margin:0!important;padding:0!important;border:none;background-color:#013b1f}.mixed_output_NoFormat{font-family:Consolas,monospace;color:#dcdcdc;border:none;background-color:#013b1f;margin:0;padding:0}.mixed_output_NoFormat pre{line-height:1.35;color:#dcdcdc;margin:0;padding:0}.mixed_output_NoFormat pre code{margin:0!important;padding:0!important;border:none;background-color:#013b1f}.mixed_output_inline{color:#dcdcdc;font-family:Consolas,monospace;background-color:#013b1f;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.output_box{margin:0;padding:0}.output_box details>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6b4b;cursor:pointer;color:#fff;box-shadow:3px 3px 4px #000;text-indent:0}.output_box details[open]>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6b4b;border:#282c34;border-width:1px;border-style:solid}.output_box{padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:1em}.code_NoFormat{line-height:1.45;margin:0;padding:0;background-color:#001029}.code_NoFormat pre{margin:0;padding:0;background-color:#001029}.code_NoFormat pre code{font-family:"Cascadia Mono",monospace;margin:0!important;padding:0!important;border:none;background-color:#001029}.code_NoFormat p{padding:0;margin:0}.code_inline{background-color:#001029;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.code_box{margin:0;padding:0}.code_box details>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6388;cursor:pointer;color:#fff;box-shadow:3px 3px 4px #000;text-indent:0}.code_box details[open]>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6388;border:#282c34;border-width:1px;border-style:solid}.code_box{padding-top:0;padding-bottom:0;margin-top:0;margin-bottom:1em}.hide_tab{padding-top:0;padding-bottom:0;margin-top:0;margin-bottom:1em}.hide_tab>details>summary{max-width:100%;min-width:30px;width:fit-content;padding-left:11px;padding-right:0;padding-bottom:0;background-color:#3f6388;cursor:pointer;color:#fff;text-indent:0;border:#282c34;border-width:1px;border-style:solid}.hide_tab>details[open]>summary .closed_text{display:none}.hide_tab>details>summary .closed_text{padding-left:1em;padding-right:1em;margin-left:.25em;display:inline-block;border-left:#282c34;border-width:1px;border-style:solid;border-bottom:none;border-top:none;border-right:none}.hide_tab>details[open]>summary{position:absolute;width:35px;max-width:90%;height:1.94em;padding-bottom:0;padding-top:3px;padding-left:12px;padding-right:5px;background-color:#3f6388;border:#282c34;border-width:1px;border-style:solid;border-bottom:none}.tab_wrapper{width:100%;display:inline-block}.tab_wrapper .tab_code_links{background-color:#001029}.tab_wrapper .tab_code_links .tablink{background-color:#3f6388;color:#fff;float:left;border:1px solid #000;outline:0;cursor:pointer;padding:2px 20px;width:max-content;height:auto}.tab_wrapper .tab_code_links .tablink.first_tab{padding-left:54px}.tab_wrapper .tab_code_links .tablink.active{font-weight:500;background-color:rgba(82,127,173,.836)}.tab_wrapper .tab_code_links .tablink:hover{background-color:rgba(82,127,173,.836)}.tab_wrapper .tabcontent{background-color:#001029;display:none;width:100%;float:left;margin:0;padding:0}.tab_wrapper .tabcontent.active{display:block}.code_in_modal{background-color:#001029;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.output_in_modal{background-color:#013b1f}.img_output,.img_output_in_modal{text-indent:0;margin:0;padding:0;background-color:#181818}.img_output_in_modal_old,.img_output_old{text-indent:0;margin:0;padding:0;background-color:#1e1e1e}.sign_output{color:#fff;width:100%;max-width:100%;height:auto;padding-bottom:0;padding-top:0;padding-left:12px;padding-right:12px;background-color:#3f6b4b;border:#282c34;border-width:1px;border-style:solid;margin-bottom:0;padding-top:0}.outputmodal_container{padding:0;margin:0}</style><style>.gif_output_in_modal{text-indent:0;margin:0;padding:0;background-color:#181818}.gif_output{position:relative;display:inline-block;cursor:pointer;margin:0;padding:0;max-width:100%}.gif-wrapper{display:block;visibility:hidden;margin:0;padding:0;max-width:100%}.gif-wrapper.playing{visibility:visible}.play-overlay{position:absolute;top:0;left:0;right:0;bottom:0;background-color:#181818;background-color:#000;display:flex;justify-content:center;align-items:center}.play-overlay.hidden{background:0 0}.play-button{background:0 0;border:none;color:#fff;cursor:pointer;padding:0;transform:scale(.5);transition:background .3s}.play-overlay.hidden .play-button{display:none}</style><script>function setMaxHeight(){const e=document.querySelectorAll(".gif-wrapper");let t=0;e.forEach(e=>{const o=e.offsetHeight;o>t&&(t=o)}),e.forEach(e=>{e.style.height=`${t}px`,e.style.width="auto"})}document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".gif_output");let t=0;e.forEach(o=>{const n=o.querySelector(".gif-wrapper"),c=o.querySelector(".play-overlay");let l=!1;n.onload=function(){t++,t===e.length&&setMaxHeight()},o.addEventListener("click",function(){l?(n.classList.remove("playing"),c.classList.remove("hidden"),l=!1):(n.classList.add("playing"),c.classList.add("hidden"),l=!0)})})})</script><div class="bar_top"><ul><li><div style="text-indent:0"><button class="modalButton" style="background-color:transparent;color:#fff;display:block;margin-bottom:-2px"><img src="/julia_book/assets/icons/sheets01.png" style="width:auto;height:30px;opacity:.9;padding-bottom:5px;margin-left:0"> Sections</button></div><div class="modal" id="modal_bar"><div class="modal-content"><div class="modal-header"><h2 style="text-decoration:none"><span style="text-decoration:underline">PART II</span>: HIGH PERFORMANCE</h2></div><div class="modal-body"><div class="row"><div class="column"><div style="padding-bottom:.8em"></div><ul><li>7. <u>Introduction to Performance</u><ul><li><a href="/julia_book/PAGES/07a_overview/"><i>a</i>. Overview and Goals</a></li><br><li><a href="/julia_book/PAGES/07b_introPerformace/"><i>b</i>. When To Optimize Code?</a></li><br><li><a href="/julia_book/PAGES/07c_benchmarks/"><i>c</i>. Benchmarking Execution Time</a></li><br><li><a href="/julia_book/PAGES/07d_TS-onTypes/"><i>d</i>. Preliminaries on Types</a></li><br><li><a href="/julia_book/PAGES/07e_TS-onFunctions/"><i>e</i>. Functions: Type Inference and Multiple Dispatch</a></li><br></ul></li></ul></div><div class="column"><div style="padding-bottom:.8em"></div><ul><li>8. <u>Type Stability</u><ul><li><a href="/julia_book/PAGES/08a_overview/"><i>a</i>. Overview and Goals</a></li><br><li><a href="/julia_book/PAGES/08b_TS-definition/"><i>b</i>. Defining Type Stability</a></li><br><li><a href="/julia_book/PAGES/08c_TS-scalarsVectors/"><i>c</i>. Type Stability with Scalars and Vectors</a></li><br><li><a href="/julia_book/PAGES/08d_TS-globalVariables/"><i>d</i>. Type Stability with Global Variables</a></li><br><li><a href="/julia_book/PAGES/08e_TS-barrierFunctions/"><i>e</i>. Barrier Functions</a></li><br><li><a href="/julia_book/PAGES/08f_TS-tuples/"><i>f</i>. Type Stability with Tuples</a></li><br><li><a href="/julia_book/PAGES/08g_TS-highOrderFunctions/"><i>g</i>. Type Stability with Higher-Order Functions</a></li><br><li><a href="/julia_book/PAGES/08h_TS-gotchas/"><i>h</i>. Gotchas for Type Stability</a></li><br></ul></li></ul></div><div class="column"><div style="padding-bottom:.8em"></div><ul><li>9. <u>Reducing Memory Allocations</u><ul><li><a href="/julia_book/PAGES/09a_overview/"><i>a</i>. Overview and Goals</a></li><br><li><a href="/julia_book/PAGES/09b_onAllocations/"><i>b</i>. Stack vs Heap</a></li><br><li><a href="/julia_book/PAGES/09c_objectsAllocating/"><i>c</i>. Objects Allocating Memory</a></li><br><li><a href="/julia_book/PAGES/09d_views/"><i>d</i>. Slice Views to Decrease Allocations</a></li><br><li><a href="/julia_book/PAGES/09e_preallocations/"><i>e</i>. Pre-Allocations</a></li><br><li><a href="/julia_book/PAGES/09f_reductions/"><i>f</i>. Reductions</a></li><br><li><a href="/julia_book/PAGES/09g_staticVectors/"><i>g</i>. Static Vectors for Small Collections</a></li><br><li><a href="/julia_book/PAGES/09h_lazyOperations/"><i>h</i>. Lazy Operations</a></li><br><li><a href="/julia_book/PAGES/09i_lazyBroadcasting/"><i>i</i>. Lazy Broadcasting and Loop Fusion</a></li><br></ul></li></ul></div></div><div class="row"><div class="column"><div style="padding-bottom:.8em"></div><ul><li>10. <u>Vectorization (SIMD)</u><ul><li><a href="/julia_book/PAGES/10a_overview/"><i>a</i>. Overview and Goals</a></li><br><li><a href="/julia_book/PAGES/10b_macrosAlgorithms/"><i>b</i>. Macros as a Means for Optimizations</a></li><br><li><a href="/julia_book/PAGES/10c_simd_intro/"><i>c</i>. Introduction to SIMD</a></li><br><li><a href="/julia_book/PAGES/10d_simd_independence/"><i>d</i>. SIMD: Independence of Iterations</a></li><br><li><a href="/julia_book/PAGES/10e_simd_unitStrides/"><i>e</i>. SIMD: Contiguous Access and Unit Strides</a></li><br><li><a href="/julia_book/PAGES/10f_simd_branchless/"><i>f</i>. SIMD: Branchless Code</a></li><br><li><a href="/julia_book/PAGES/10g_simd_LoopVectorization/"><i>g</i>. SIMD Packages</a></li><br></ul></li></ul></div><div class="column"><div style="padding-bottom:.8em"></div><ul><li>11. <u>Multithreading</u><ul><li><a href="/julia_book/PAGES/11a_overview/"><i>a</i>. Overview and Goals</a></li><br><li><a href="/julia_book/PAGES/11b_multithread_intro/"><i>b</i>. Introduction to Multithreading</a></li><br><li><a href="/julia_book/PAGES/11c_multithread_tasks/"><i>c</i>. Task-Based Parallelism: @spawn</a></li><br><li><a href="/julia_book/PAGES/11d_multithread_safe/"><i>d</i>. Thread-Safe Operations</a></li><br><li><a href="/julia_book/PAGES/11e_multithread_loops/"><i>e</i>. Parallel For-Loops: @threads</a></li><br><li><a href="/julia_book/PAGES/11f_multithread_apply/"><i>f</i>. Parallelization in Practice</a></li><br><li><a href="/julia_book/PAGES/11g_multithread_packages/"><i>g</i>. Multithreading Packages</a></li><br></ul></li></ul></div><div class="column"><div style="padding-bottom:.8em"></div></div></div></div></div></div></li></ul></div><style>.bar_top{padding-left:160px}.bar_top{background-image:linear-gradient(to right,#000,#000 10%,#3f6388 55%,#3f6388);position:fixed;width:100%;height:48px;top:0;left:0;padding:8px 0 10px 0;font-size:110%;z-index:125;font-family:Inter}.bar_top a:hover{color:#a09f9f}.bar_top>ul{list-style-type:none;float:left;position:relative;bottom:0;padding-left:1%;left:160px}.bar_top li a{color:#fff}.bar_top .modal{background-color:transparent;margin-top:48px;padding-left:1%;margin-left:0;width:100%;height:100%;overflow:auto;position:fixed}.bar_top .modal-content{position:relative;width:1200px;max-width:90%;height:max-content;max-height:90%;background-color:#000;margin:auto;padding:8px;margin-left:160px;-webkit-animation-name:none;animation-name:none}.bar_top .modal-header{background-color:#000;color:#fff}.bar_top .modal-body{color:#649dd6}.bar_top .modal-body .row{display:flex}.bar_top .modal-body .row .column{flex:1}.bar_top .modal-body .row h3{padding-bottom:.5em}.bar_top .modal-body .row ul li{line-height:1}.bar_top .modal-body .row ul li ul{list-style-type:none;margin:0;padding:0;padding-top:.5em;padding-bottom:.4em;line-height:1}.bar_top .modal-body .row ul li ul li{line-height:1}.bar_top .modal-body .row li{line-height:1;list-style-type:none;float:center;text-indent:-20px;padding-left:22px;position:relative}.bar_top .modal-body .row .column{text-align:center}.bar_top .modal-body .row .column h3{text-align:center}.bar_top .modal-body .row .column ul{text-align:left;margin-left:auto;margin-right:auto;list-style-position:inside;line-height:.55em}.bar_top .modalButton{border:none;margin-bottom:24px;box-shadow:none}.bar_top .modalClose{font-size:0px}</style><style>.footn{position:relative;display:inline-block;margin-left:-.6em;margin-right:0;color:#2669dd;text-decoration:underline}.supr{vertical-align:80%;font-size:75%;line-height:1}.footn .footn_text{font-size:125%;visibility:hidden;text-align:justify;text-justify:inter-word;text-indent:0;line-height:1.5;background-color:#282c34;color:#e0e4eb;border-radius:6px;padding:5px 12px 5px 12px;position:absolute;z-index:1;bottom:100%;right:0}.footn .footn_text.left{left:0;width:max-content;max-width:500px}.footn .footn_text.right{right:0;width:max-content;max-width:500px}.footn:hover .footn_text{visibility:visible}.footn a{color:#7b9fdd}.footn a:hover{color:#a1b6dbb2}</style><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js"></script><script>$(document).ready(function(){$(".footn.supr").hover(function(){var t=$(this).find(".footn_text"),e=$(this).closest("p"),o=e.width(),s=t.offset().left-e.offset().left>o/2;t.removeClass("left right"),s?t.addClass("right"):t.addClass("left"),t.addClass("hovering")},function(){$(this).find(".footn_text").removeClass("hovering"),$(this).find(".footn_text").removeClass("left right")})})</script><style>@media (max-width:768px){.footn .footn_text.left{left:0;width:max-content;max-width:200px}.footn .footn_text.right{right:0;width:max-content;max-width:200px}}</style><style>@media (max-width:850px){.jumbotron{font-size:90%!important}.franklin-content{font-size:100%!important}.franklin-content{padding-left:1%;padding-right:1%}.franklin-content .container{max-width:100%!important}.index_container,.index_container section{font-size:100%}.index_container{padding-left:1%;padding-right:1%}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}.home_container section{font-size:100%;line-height:1.55em}.home_container ul li{padding-right:1%;padding-left:0}.home_container ul{padding-right:0;padding-left:0}.home_container .row li{padding-left:0;padding-bottom:1.55em;margin-left:0}.home_container .bullets_nomarker ul li p{line-height:1.55!important}.col-lg-.mx-auto{overflow:auto!important}.jumbotron{padding-left:60px!important;padding-right:1%!important;padding-top:0;margin-top:0}.modal{padding:2px!important}.bullets ol,.itemNoSpace ol{padding:4px}.bullets ul li,.itemNoSpace ul li{padding-right:5%;padding-left:0;margin-left:0}.bullets ul li p,.itemNoSpace ul li p{line-height:1.65}}@media (max-height:600px){.jumbotron{font-size:90%!important}.franklin-content{font-size:100%!important}.franklin-content .container{max-width:100%!important}.index_container,.index_container section{font-size:100%}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}.index_container{padding-left:1%;padding-right:1%}.col-lg-.mx-auto{overflow:auto!important}.jumbotron{padding-left:60px!important;padding-right:1%!important;padding-top:0;margin-top:0}.franklin-content{padding-left:0!important}.modal{padding:2px!important}.bullets ol,.itemNoSpace ol{padding:6px}.bullets ul li,.itemNoSpace ul li{padding-right:5%;padding-left:0;margin-left:0}.bullets ul li p,.itemNoSpace ul li p{line-height:1.55}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}}</style><div class="left_bar_mobile" style="color:#fff"><ul><li><a href="/julia_book/index.html"><img src="/julia_book/assets/icons/home.png" style="width:15%;height:auto;opacity:.9;padding-bottom:0"> HOME</a></li><li><a href="/julia_book/list_posts/"><img src="/julia_book/assets/icons/books03.png" style="width:15%;height:auto;opacity:.9;padding-bottom:0"> CHAPTERS</a></li><li><div class="dark-mode-mobile"><label class="switch"><input type="checkbox" class="toggleMobile"> <span class="slider round"></span></label></div></li></ul></div><style>@media (min-width:850px),(min-height:600px){.left_bar_mobile{display:none}}@media (max-width:850px),(max-height:600px){.left_bar_mobile{display:block}.left_bar_mobile img{display:none}.left_bar_mobile{z-index:200;background-image:none;position:absolute;font-family:Inter;height:160px!important;top:0;left:0;font-size:85% width : 60px}.left_bar_mobile ul{list-style-type:none;float:left;font-size:100%;position:relative;padding-left:.4em;padding-top:.2em;line-height:2em!important;height:100%;top:0;width:60px;display:flex;flex-direction:column;justify-content:space-around}.left_bar_mobile li{flex:1}.left_bar_mobile li a{color:#fff}.left_bar_mobile a:hover{color:#a09f9f}.dark-mode-mobile{position:relative;bottom:0;margin-top:auto}.dark-mode-mobile .switch{width:40px;height:20px}.dark-mode-mobile .slider:before{height:15px;width:15px}.dark-mode-mobile input:checked+.slider:before{transform:translateX(20px)}@media (max-width:850px),(max-height:600px){h2{font-size:140%;padding-top:1em}h1{font-size:180%;padding-top:.5em;padding-bottom:0}}}</style><style>@media (max-width:850px),(max-height:600px){.lead{display:none}.bar_top,.copy-button,.py-1 .container .center-text,nav{display:none!important}.jumbotron{padding-left:80px;padding-right:.1%!important;padding-top:0;margin-top:0}}</style><style>@media (min-width:850px),(min-height:600px){.dark-mode-mobile{visibility:hidden}}@media (max-width:850px),(max-height:600px){.dark-mode-mobile{visibility:visible}}</style><script>document.querySelector(".toggleMobile").addEventListener("change",function(){const e=document.documentElement;this.checked?(e.classList.add("dark-mode"),localStorage.setItem("darkMode","enabled")):(e.classList.remove("dark-mode"),localStorage.setItem("darkMode","disabled"))}),window.addEventListener("load",function(){const e=document.documentElement;"enabled"===localStorage.getItem("darkMode")?(document.querySelector(".toggleMobile").checked=!0,e.classList.add("dark-mode")):document.querySelector(".toggleMobile").checked=!1})</script><div class="franklin-content"><section id="introduction" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Introduction</h2><p></p><p>So far, we&#39;ve explored two macros for parallelization: <code>@spawn</code> and <code>@threads</code>. The macro <code>@spawn</code> provides granular control over the parallelization process, letting users explicitly define the tasks to be executed concurrently. In contrast, <code>@threads</code> offers a simpler approach for parallelizing for-loops, where iterations are automatically partitioned into tasks according to the number of available threads.</p><p>Furthermore, we&#39;ve pointed out that, due to inherent dependencies between computations, not all workloads are equally amenable to parallelization. Focusing on programs that aren&#39;t embarrassingly parallel, we&#39;ve demonstrated that a naive approach to parallelization can lead to severe issues.</p><p>Overall, our discussions to this point have largely focused on the <em>syntax</em> and <em>work distribution</em> of these approaches. Therefore, we have yet to address how to apply multithreading in real scenarios. Furthermore, given the possibility of dependencies between computations, <em>how</em> to parallelize is only part of the challenge: knowing <em>when</em> to parallelize is equally important.</p><p>This section and the next one aim to bridge this gap, providing practical guidance on implementing multithreading. We begin by highlighting the advantages of coarseâ€‘grained parallelization over fine-grained parallelization. By dividing the workload into a small number of large tasks, coarseâ€‘grained parallelization reduces the scheduling overhead from managing numerous lightweight tasks.</p><p>After this, we revisit the parallelization of for-loops, this time using <code>@spawn</code>. In particular, leveraging the additional control that <code>@spawn</code> provides over task creation, we&#39;ll demonstrate how to apply multithreading in the presence of a ubiquitous type of dependency: reductions.</p><p>We conclude by showing a performance issue arising with multithreading, known as false sharing. While this doesn&#39;t affect the correctness the result, it can slow down computations if not addressed.</p><p></p></div></div></div></section><section id="better_to_parallelize_at_the_top" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Better To Parallelize at The Top</h2><p></p><p>Given the overhead involved in multithreading, there&#39;s an inherent trade-off between creating new tasks and fully utilizing machine resources. This is why we must always consider whether parallelizing our code is worthwhile in the first place. For instance, when it comes to operations over collections, multithreading is only justified if the collections are large enough to offset the associated overhead. Otherwise, single-threaded approaches will consistently outperform parallelized ones.</p><p>In case multithreading is deemed beneficial, we immediately face another decision: at what level code should be parallelized. Next, we&#39;ll demonstrate that <strong>parallelism at the highest possible level is preferable to multithreading individual operations</strong>. In this way, we minimize the overhead of task creation.</p><p>Note that the level of parallelization is always constrained by the degree of dependency between operations. Hence, our qualification of highest <strong>possible</strong> level. For instance, in problems requiring strictly serial computation, the best we can achieve is parallelization within each individual step.</p><p>To illustrate this, let&#39;s consider a for-loop where each iteration needs to sequentially compute three operations.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Julia's Default</button> <button class="tablink" data-id="">Parallelization at The Highest Level Possible</button> <button class="tablink" data-id="">Each Operation Parallelized</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function all_steps&#40;a&#41; 
   y      &#61; step1&#40;a&#41;
   z      &#61; step2&#40;y&#41;
   output &#61; step3&#40;z&#41;

   return output
end

function foo&#40;x&#41;
   output &#61; similar&#40;x&#41;

   for i in eachindex&#40;output&#41;
      output&#91;i&#93; &#61; all_steps&#40;x&#91;i&#93;&#41;
   end

   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  5.000 Î¼s (3 allocations: 7.883 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_large&#41;</code><br><pre><code class="plaintext code-output">  527.133 Î¼s (3 allocations: 781.320 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function all_steps&#40;a&#41; 
   y      &#61; step1&#40;a&#41;
   z      &#61; step2&#40;y&#41;
   output &#61; step3&#40;z&#41;

   return output
end

function foo&#40;x&#41;
   output &#61; similar&#40;x&#41;

   @threads for i in eachindex&#40;output&#41;
      output&#91;i&#93; &#61; all_steps&#40;x&#91;i&#93;&#41;
   end

   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  11.289 Î¼s (125 allocations: 20.508 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_large&#41;</code><br><pre><code class="plaintext code-output">  54.258 Î¼s (125 allocations: 793.945 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function parallel_step&#40;f, x&#41;
   output &#61; similar&#40;x&#41;

   @threads for i in eachindex&#40;output&#41;      
      output&#91;i&#93; &#61; f&#40;x&#91;i&#93;&#41;
   end

   return output
end

function foo&#40;x&#41;
   y      &#61; parallel_step&#40;step1, x&#41;
   z      &#61; parallel_step&#40;step2, y&#41;
   output &#61; parallel_step&#40;step3, z&#41;
   
   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  33.472 Î¼s (375 allocations: 61.523 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_big&#41;</code><br><pre><code class="plaintext code-output">  91.834 Î¼s (375 allocations: 2.326 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>The examples illustrate the two-step process outlined. First, it shows that parallelization is advantageous only with large collections. Otherwise, the question of whether to parallelize shouldn&#39;t even arise. Second, once multithreading is deemed beneficial, it demonstrates that grouping all operations into a single task is faster than parallelizing each operation individually.</p><h4>Implications</h4><p>The strategy of parallelizing code at the highest possible level has significant implications for program design, particularly when the program will eventually be applied to multiple independent objects. It suggests a practical guideline: start by implementing the code for a single object, without introducing parallelism. After thoroughly optimizing the single-case code, parallel execution can then be seamlessly integrated at the top level. The approach not only improves performance, but also simplifies the development by making debugging and testing more straightforward.</p><p>A common example of this strategy appears in scientific simulations, where many independent runs of the same model must be executed. In such cases, the most effective method is to maintain a singleâ€‘threaded codebase for the model itself, and then run multiple instances of that model in parallel. This ensures that each run is as efficient as possible, while still taking full advantage of available computing resources.</p><p></p></div></div></div></section><section id="the_importance_of_work_distribution" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>The Importance of Work Distribution</h2><p></p><p>Multithreading performance is heavily influenced by how evenly the computational workload is distributed across iterations. The <code>@threads</code> macro is highly effective when each iteration requires roughly equal processing time, since the tasks it spawns will contain an equal amount of iterations. However, scenarios with uneven computational effort can pose significant challenges. In such cases, some threads may remain idle while others are heavily loaded, dramatically reducing the potential performance gains of parallel processing.</p><p>To address this issue, we need greater control over how work is distributed among threads. This calls for the use of <code>@spawn</code>.</p><p>One strategy is to make each iteration a separate task. However, this approach becomes extremely inefficient if there&#39;s a large number of iterations: creating far more tasks than there are threads introduces substantial and unnecessary overhead. The following example illustrates this effect, showing that spawning one task per iteration can result in extremely slow execution times.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @threads for i in eachindex&#40;x&#41;
        output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  4.907 ms (125 allocations: 76.309 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @sync for i in eachindex&#40;x&#41;
        @spawn output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  11.284 s (60005935 allocations: 5.277 GiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>An alternative strategy, which lets users fine-tune the workload of each task, is to partition iterations into smaller subsets that can be processed in parallel. Before detailing the implementation, we&#39;ll first explore how to partition a collection and its indices. This step makes use of the <code>ChunkSplitters</code> package.</p><h4>Partitioning Collections</h4><p>The package <code>ChunkSplitters</code> makes it possible to partition a collection <code>x</code> and its indices. It provides two functions for <em>lazy</em> partitioning: <code>chunks</code> and <code>index_chunks</code>. These functions support <code>n</code> and <code>size</code> as keyword arguments, depending on the type of partition desired. Specifically, <code>n</code> sets the number of subsets to create, with each subset sized to distribute elements evenly. In contrast, <code>size</code> specifies the number of elements to be contained in each subset. Since an even distribution across all subsets can&#39;t be guaranteed, the package adjusts the number of elements in one of the subsets if necessary.</p><p>Below, we apply these functions to a variable <code>x</code> containing the 26 letters of the alphabet. Note that outputs require the use of <code>collect</code>, since <code>chunks</code> and <code>index_chunks</code> are lazy.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Partition By Number of Chunks</button> <button class="tablink" data-id="">Partition By Size of Chunks</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; 5

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">5-element Vector{UnitRange{Int64}}:
 1:6
 7:11
 12:16
 17:21
 22:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">5-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b", "c", "d", "e", "f"]
 ["g", "h", "i", "j", "k"]
 ["l", "m", "n", "o", "p"]
 ["q", "r", "s", "t", "u"]
 ["v", "w", "x", "y", "z"]</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

chunk_length  &#61; 10

chunk_indices &#61; index_chunks&#40;x, size &#61; chunk_length&#41;
chunk_values  &#61; chunks&#40;x, size &#61; chunk_length&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">3-element Vector{UnitRange{Int64}}:
 1:10
 11:20
 21:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">3-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"]
 ["k", "l", "m", "n", "o", "p", "q", "r", "s", "t"]
 ["u", "v", "w", "x", "y", "z"]</code></pre></div></div></div></div></div><p></p></details></div><p>A relevant type of partition for multithreading is given by a number of chunks proportional to the number of worker threads. The example below implements this partition. It generates both chunk indices and chunk values.</p><p>Since this partition approach will eventually be used with for-loops, we also show how to use <code>enumerate</code> to pair each chunk with the values or subindices of its corresponding subset.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Partition By Number of Threads</button> <button class="tablink" data-id="">Partition By Number of Threads - Enumerate</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; nthreads&#40;&#41;

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{UnitRange{Int64}}:
 1:2
 3:4
 â‹®
 25:25
 26:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b"]
 ["c", "d"]
 â‹®
 ["y"]
 ["z"]</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; nthreads&#40;&#41;

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;

chunk_iter1   &#61; enumerate&#40;chunk_indices&#41;    # pairs &#40;i_chunk, chunk_index&#41;
chunk_iter2   &#61; enumerate&#40;chunk_values&#41;     # pairs &#40;i_chunk, chunk_value&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_iter1&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{Tuple{Int64, UnitRange{Int64}}}:
 (1, 1:2)
 (2, 3:4)
 â‹®
 (23, 25:25)
 (24, 26:26)</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_iter2&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{Tuple{Int64, SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}}:
 (1, ["a", "b"])
 (2, ["c", "d"])
 â‹®
 (23, ["y"])
 (24, ["z"])</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><section id="work_distribution_defining_tasks_through_chunks" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Work Distribution: Defining Tasks Through Chunks</h2><p></p><p>After covering how to partition datasets with the <code>ChunkSplitters</code> package, we can now turn to its role in multithreading. By dividing iterations into well-balanced chunks, we can assign each subset as an independent task to be processed concurrently.</p><p>Below, we parallelize a for-loop with <code>@threads</code>. Then, we present an equivalent implementation with <code>@spawn</code>. This requires defining a number of chunks that equals the number of worker threads.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button> <button class="tablink" data-id="">@spawn (equivalent)</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @threads for i in eachindex&#40;x&#41;
        output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  4.907 ms (125 allocations: 76.309 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.143 ms (157 allocations: 76.311 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;
    task_indices &#61; Vector&#123;Task&#125;&#40;undef, nr_chunks&#41;

    for &#40;i, chunk&#41; in enumerate&#40;chunk_ranges&#41;
        task_indices&#91;i&#93; &#61; @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return wait.&#40;task_indices&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.816 ms (151 allocations: 76.310 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>Unlike <code>@threads</code>, the <code>@spawn</code> macro offers finer control over how tasks are allocated to threads. This flexibility means we&#39;re not constrained to replicate the <code>@threads</code>&#39;s behavior. For example, we could adopt different partitioning strategies where the number of chunks is proportional to the number of worker threads, as shown in the following examples.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@spawn</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 1 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.477 ms (157 allocations: 76.311 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 2 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  8.792 ms (302 allocations: 76.325 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 4 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  6.885 ms (590 allocations: 76.352 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function compute&#33;&#40;output, x, chunk&#41;
     @turbo for j in chunk 
        output&#91;j&#93; &#61; log&#40;x&#91;j&#93;&#41;
     end
end

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn compute&#33;&#40;output, x, chunk&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 1 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.040 ms (133 allocations: 76.310 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 2 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  8.314 ms (254 allocations: 76.323 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 4 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.049 ms (494 allocations: 76.347 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><section id="handling_dependencies" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Handling Dependencies</h2><p></p><p>So far, our discussion of parallelization has focused on embarrassingly parallel for-loops, where iterations are completely independent. In such cases, each iteration can be executed in isolation, making parallelization straightforward.</p><p>In contrast, when operations exhibit dependencies, the situation becomes more complex. Attempting to parallelize without first addressing these dependencies can lead not only to inefficiencies and wasted resources, but most critically to incorrect results.</p><p>The issue occurs because thereâ€™s no oneâ€‘sizeâ€‘fitsâ€‘all method for handling dependencies. The appropriate strategy depends on the structure of the specific program. In all cases, though, the approach will require adapting the parallelization technique to work on a reformulated version of the problem. This reformulation must ensure that the tasks to be parallelized are independentâ€”ultimately, parallelization is only possible if independence of operations can be achieved.</p><p>Note that, once dependencies are present, some portion of the work will inevitably be non-parallelizable. In fact, in certain cases no subset of independent tasks exists at all, as in computations that are inherently sequential.</p><p></p></div></div></div></section><section id="handling_reductions" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Handling Reductions</h2><p></p><p>A prominent example where dependencies between iterations arise is in reductions. To address these dependencies and still benefit from parallelization, the computation must be restructured. The standard approach is to divide the data into chunks, perform partial reductions on each chunk in parallel, and then combine the partial results in a final reduction step. This transformation removes the original dependency between iterations, because each partial reduction operates on a disjoint subset of the data.</p><p>To illustrate, let&#39;s compute the sum of elements of a vector <code>x</code>. The implementation follows a variant of the partitioning techniques discussed earlier, using <code>ChunkSplitters</code> to divide the data into independent segments.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Julia's Default (Sequential)</button> <button class="tablink" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; 0.

    for i in eachindex&#40;x&#41;
        output &#43;&#61; x&#91;i&#93;
    end

    output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  5.108 ms (0 allocations: 0 bytes)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        partial_outputs&#91;i&#93; &#61; sum&#40;@view&#40;x&#91;chunk&#93;&#41;&#41;
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  1.194 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
         
    @sync for &#40;i, chunk&#41; in enumerate&#40;chunk_ranges&#41;
        @spawn partial_outputs&#91;i&#93; &#61; sum&#40;@view&#40;x&#91;chunk&#93;&#41;&#41;
    end
        
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  1.169 ms (156 allocations: 13.781 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><section id="false_sharing" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>False Sharing</h2><p></p><p>So far, weâ€™ve focused on constraints on parallelization due to dependencies between operations. But even when those dependencies are eliminated and the parallelized units are logically independent, performance can still be limited by hardware-level effects. One common culprit is cache contention, where multiple processor cores compete for shared cache resources. A particular manifestation of this issue, known as <span style="color:#3e79b4"><strong>false sharing</strong></span>, occurs when multiple cores access data stored in the same cache line. Understanding this issue requires grasping how CPU caches function.</p><p>Processors use caches to store copies of frequently accessed data. They represent a smaller and faster memory unit than RAM, and are organized into fixed-size blocks called cache lines &#40;typically 64 bytes&#41;. When data is needed, the processor first checks the cache. If the data isn&#39;t found, this must be retrieved from RAM and store a copy in the cache, a process that&#39;s significantly slower.</p><p>When multiple cores access data within the same cache line, the transfer of data follows a cache coherency protocol. This is designed to maintain data consistency across cores. This protocol can lead to situations where one core accesses data that isn&#39;t modified by another core, yet shares a cache block with altered data. In such cases, the entire cache line may be invalidated, forcing the cores to reload the entire cache block, despite there being no logical necessity to do so. This phenomenon is known as false sharing, and can cause unnecessary cache invalidations and refetches. The consequence is a significant degradation of the program&#39;s performance, particularly if threads frequently modify their variables.</p><p>While false sharing can occur in various multithreading scenarios, it&#39;s particularly prevalent in reduction operations. This case will be our focus next.</p><h4>False Sharing In Reductions: An Illustration and Solutions</h4><p>Let&#39;s consider a simple scenario where the elements of a vector are summed after applying a logarithmic transformation. We&#39;ll present two multithreaded implementations to illustrate the impact of false sharing on performance.</p><p>The first implementation is a naive approach that closely resembles a typical sequential implementation. Its goal is to illustrate false sharing. The issue arises because multiple threads are repeatedly reading and writing adjacent memory locations in the <code>partial_outputs</code> vector. Since CPU cache lines typically span several vector elements, this leads to cache invalidation and forced synchronization between cores.</p><p>In contrast, the second implementation avoids false sharing, and we&#39;ll analyze why this is so after presenting the code snippets.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Sequential</button> <button class="tablink" data-id="">False Sharing</button> <button class="tablink" data-id="">Local Variable (@threads)</button> <button class="tablink" data-id="">Local Variable (@spawn)</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; 0.

    for i in eachindex&#40;x&#41;
        output &#43;&#61; log&#40;x&#91;i&#93;&#41;
    end

    output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  35.349 ms (0 allocations: 0 bytes)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; zeros&#40;length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        for j in chunk
            partial_outputs&#91;i&#93; &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  14.018 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; zeros&#40;length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        temp &#61; 0.0
        for j in chunk
            temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
        partial_outputs&#91;i&#93; &#61; temp
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  3.621 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; zeros&#40;length&#40;chunk_ranges&#41;&#41;    
    
    @sync for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        @spawn begin
            temp &#61; 0.0
            for j in chunk
                temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
            end
            partial_outputs&#91;i&#93; &#61; temp
        end
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  3.407 ms (156 allocations: 13.781 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>To address false sharing in parallel reductions, there are several strategies that can be employed. All of them aim to prevent threads from repeatedly accessing the same cache line.</p><p>The previous example already presented one solution. It involves introducing a thread-local variable called <code>temp</code> to accumulate results. In this way, each thread maintains its own accumulator, writing to the shared array only once at the end.</p><p>Two additional solutions are presented below. The first one entails computing the reduction through a separate function. This addresses false sharing by the same logic as before, where the accumulation is done through a variable local to a function. The second solution involves defining <code>partial_outputs</code> as a matrix with extra rows &#40;seven in particular&#41;, a technique known as vector padding. This approach guarantees that each thread&#39;s accumulator is allocated on a different cache line, so that concurrent updates don&#39;t interfere with each other at the cache level.</p><p></p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Function</button> <button class="tablink" data-id="">Padding</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function compute&#40;x, chunk&#41;
    temp &#61; 0.0

    for j in chunk
        temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
    end
    
    return temp
end

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; zeros&#40;length&#40;chunk_ranges&#41;&#41;    
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        partial_outputs&#91;i&#93; &#61; compute&#40;x, chunk&#41;
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  3.623 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges     &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;    
    partial_outputs  &#61; zeros&#40;7, length&#40;chunk_ranges&#41;&#41;    
        
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        for j in chunk 
            partial_outputs&#91;1,i&#93; &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
    end
    
    return sum&#40;@view&#40;partial_outputs&#91;:,1&#93;&#41;&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  3.843 ms (124 allocations: 14.500 KiB)
</code></pre></div></div></div></div></div><p></p></details></div></div></div></div></section><footer class="py-1"><div class="container"><span class="left-text"><a href="/julia_book/PAGES/11e_multithread_loops" class="prevPage"><img src="/julia_book/assets/icons/prev-page.png" style="width:50px;height:auto;opacity:.9;padding-bottom:5px"> Previous Section <span class="ctrl-text">( <kbd>Ctrl + <img src="/julia_book/assets/icons/arrow_left.png" style="width:15px;height:auto;opacity:.9;padding-bottom:2px"> </kbd>)</span> </a></span><span class="right-text"><a href="/julia_book/PAGES/11g_multithread_packages" class="nextPage">Next Section <span class="ctrl-text">( <kbd>Ctrl + <img src="/julia_book/assets/icons/arrow_right.png" style="width:15px;height:auto;opacity:.9;padding-bottom:2px"> </kbd>)</span> <img src="/julia_book/assets/icons/next-page.png" style="width:50px;height:auto;opacity:.9;padding-bottom:5px"> </a></span><span class="center-text">Â© Martin Alfaro<br>Last Modified October 4, 2025</span></div></footer><style>@media (max-width:850px),(max-height:600px){.ctrl-text{display:none}}footer{font-family:Inter}footer .container{width:100%;margin-top:.6em;margin-bottom:.5em;overflow:hidden;text-align:center;align-items:center;justify-content:center;color:#fff}footer .center-text{text-align:center}footer .left-text{float:left}footer .right-text{float:right}footer a{color:#fff}footer a:hover{color:#fff;opacity:.9;text-decoration:none}</style><script>const prevPageURL=document.querySelector(".prevPage").href,nextPageURL=document.querySelector(".nextPage").href;function goToPrevPage(){window.location=prevPageURL}function goToNextPage(){window.location=nextPageURL}document.querySelector(".prevPage").addEventListener("click",goToPrevPage),document.querySelector(".nextPage").addEventListener("click",goToNextPage),document.addEventListener("keyup",e=>{"ArrowLeft"===e.key&&e.ctrlKey?goToPrevPage():"ArrowRight"===e.key&&e.ctrlKey&&goToNextPage()})</script></div><script src="/julia_book/libs/katex/katex.min.js"></script><script src="/julia_book/libs/katex/auto-render.min.js"></script><script>renderMathInElement(document.body)</script><script src="/julia_book/libs/highlight/highlight.js"></script><script>hljs.highlightAll(),hljs.configure({tabReplace:"    "})</script><script src="/julia_book/libs/simple-scrollspy.min.js"></script><script>window.onload=function(){scrollSpy("#navbarResponsive",{sectionClass:".scrollspy",menuActiveTarget:".nav-link",offset:100})}</script></body></html><!-- 
#################################################
# FOR ALL PAGES
################################################# 
--><script>const btns=document.getElementsByClassName("modalButton"),modals=document.getElementsByClassName("modal");[...btns].forEach((e,t)=>{e.onclick=()=>{"block"===modals[t].style.display?modals[t].style.display="none":modals[t].style.display="block"}}),window.addEventListener("click",function(e){const t=document.getElementsByClassName("modal"),l=document.getElementsByClassName("modal-content"),n=document.getElementsByClassName("modalButton");for(let s=0;s<t.length;s++){const o=t[s],a=l[s],d=n[s];"block"!==o.style.display||a.contains(e.target)||d.contains(e.target)||(o.style.display="none")}}),document.addEventListener("keydown",function(e){if(e.ctrlKey&&"z"===e.key){const e=document.getElementById("modal_bar");e&&"block"===e.style.display?e.style.display="none":e.style.display="block"}})</script><script>let handleClick=e=>{Array.from(e.target.parentElement.parentElement.querySelectorAll(".active"),e=>e.classList.remove("active")),e.target.classList.add("active"),document.querySelector(`div.tabcontent[data-id*="${e.target.dataset.id}"]`).classList.add("active")};Array.from(document.getElementsByClassName("tablink"),e=>e.addEventListener("click",handleClick,!1))</script><script>let setHeight=()=>{document.querySelectorAll(".tab_wrapper").forEach(e=>{let t=e.querySelectorAll(".tabcontent"),i=0,l=0;t.forEach(e=>{let t=e.style.visibility;e.style.visibility="visible";let o=e.style.position,s=e.style.display;e.style.position="relative",e.style.display="inline-block";let y=e.querySelector(".code_in_modal"),r=e.querySelector(".output_in_modal");if(y){y.style.height="auto";let e=y.offsetHeight;e>i&&(i=e)}if(r){r.style.height="auto";let e=r.offsetHeight;e>l&&(l=e)}e.style.visibility=t,e.style.position=o,e.style.display=s}),t.forEach(e=>{let t=e.querySelector(".code_in_modal"),o=e.querySelector(".output_in_modal");t&&(t.style.height=i+"px"),o&&(o.style.height=l+"px")})})};window.addEventListener("load",setHeight),window.addEventListener("resize",setHeight)</script><script>for(var tabWrappers=document.getElementsByClassName("tab_wrapper"),i=0;i<tabWrappers.length;i++)for(var tabWrapper=tabWrappers[i],buttons=tabWrapper.getElementsByClassName("tablink"),tabContents=tabWrapper.getElementsByClassName("tabcontent"),j=0;j<buttons.length;j++){var button=buttons[j],tabContent=tabContents[j],dataId="tab"+(i+1)+"_"+(j+1);button.setAttribute("data-id",dataId),tabContent.setAttribute("data-id",dataId)}</script><script>document.addEventListener("keydown",function(e){if("ArrowUp"===e.code&&e.altKey)for(var n=document.getElementsByTagName("details"),t=0;t<n.length;t++)n[t].open=!1})</script><script>document.addEventListener("keydown",function(e){if("ArrowDown"===e.code&&e.altKey)for(var n=document.getElementsByTagName("details"),o=0;o<n.length;o++)n[o].open=!0}),window.onkeydown=function(e){if("Escape"==e.key)for(let e of modals)e.style.display="none"}</script><style>.pic_drop_green{padding-top:1em;padding-bottom:1em}.pic_drop_green details>summary{color:#fff;display:inline-block;width:auto;cursor:pointer;padding:0 6px;margin:0;border-width:1px;border-style:solid;box-shadow:3px 3px 4px #000;background-color:#3f6b4b}.pic_drop_green details[open]>summary{width:auto;padding:0 6px;border:#a8a8a8;border-width:1px;border-style:solid;color:#fff;background-color:#3f6b4b}.pic_drop_green details>p{display:block;width:auto;padding:0;margin:0}.multiple_pics{text-align:center}.multiple_pics h2{text-decoration:none;padding-bottom:0}.multiple_pics .row{display:flex}.multiple_pics .column2{flex:50%}.multiple_pics .column3{flex:33.33%}</style><script>function generateId(e){return e.toLowerCase().replace(/[^\w\s]/g,"").replace(/\s+/g,"_")}function copyToClipboard(e){const t=document.createElement("input");document.body.appendChild(t),t.value=e,t.select(),document.execCommand("copy"),document.body.removeChild(t)}function showTooltip(e,t,n="Link Copied"){const o=document.createElement("div");o.style.position="absolute";const l=document.createElement("span");l.textContent=n,l.style.position="absolute",l.style.background="rgba(63, 99, 136, 0.75)",l.style.color="white",l.style.padding="4px 2px",l.style.borderRadius="4px",l.style.fontSize="14px",l.style.textAlign="center",l.style.fontWeight="700",o.appendChild(l),t.appendChild(o);const i=t.getBoundingClientRect(),c=e.clientX-i.left-28,d=e.clientY-i.bottom-25;l.style.top=`${d}px`,l.style.left=`${c}px`,setTimeout(()=>{t.removeChild(o)},1e3)}function handleH2Elements(){document.querySelectorAll("h2").forEach(e=>{e.addEventListener("click",function(t){const n=e.textContent.trim();copyToClipboard(`${window.location.origin}${window.location.pathname}#${generateId(n)}`),showTooltip(t,e)})})}function handleH4Elements(){document.querySelectorAll("h4").forEach(e=>{const t=`sub_${generateId(e.textContent.trim())}`;e.setAttribute("id",t);const n=document.createElement("a");n.href=`#${t}`,n.innerHTML=e.innerHTML,n.style.textDecoration="underline",e.innerHTML="",e.appendChild(n),n.addEventListener("click",function(t){copyToClipboard(n.href),showTooltip(t,e),t.preventDefault()})})}document.addEventListener("DOMContentLoaded",function(){handleH2Elements(),handleH4Elements()})</script><style>h2,h4{cursor:pointer}.hand-cursor{cursor:wait}h2:hover,h4:hover{color:rgba(0,0,0,.5)}</style><!-- 
#################################################
# FOR EACH SPECIFIC PAGE
#################################################
 --><nav class="nav"><button class="nav-toggle" aria-label="Toggle navigation"><img src="/julia_book/assets/icons/dropdown.png" style="width:auto;height:30px;opacity:.9;padding-bottom:2px;margin-left:0"> <span class="nav-title"><i>11f.</i> Parallelization in Practice</span></button><div class="nav-menu"><ul><li><a href="#introduction" data-offset="-40">Introduction</a></li><li><a href="#better_to_parallelize_at_the_top" data-offset="-40">Better To Parallelize at The Top</a></li><li><a href="#the_importance_of_work_distribution" data-offset="-40">The Importance of Work Distribution</a></li><li><a href="#work_distribution_defining_tasks_through_chunks" data-offset="-40">Work Distribution: Defining Tasks Through Chunks</a></li><li><a href="#handling_dependencies" data-offset="-40">Handling Dependencies</a></li><li><a href="#handling_reductions" data-offset="-40">Handling Reductions</a></li><li><a href="#false_sharing" data-offset="-40">False Sharing</a></li></ul></div></nav><script>const navToggle=document.querySelector(".nav-toggle"),navMenu=document.querySelector(".nav-menu"),navLinks=document.querySelectorAll(".nav-menu a");navToggle.addEventListener("click",()=>{navMenu.classList.toggle("show")}),navLinks.forEach(e=>{e.addEventListener("click",n=>{n.preventDefault();const t=document.querySelector(e.getAttribute("href")),o=parseInt(e.dataset.offset,10)||0;window.scrollTo({top:t.offsetTop+o,behavior:"smooth"})})}),document.addEventListener("click",e=>{navMenu.contains(e.target)||navToggle.contains(e.target)||navMenu.classList.remove("show")}),document.addEventListener("keydown",e=>{"Escape"===e.key&&navMenu.classList.remove("show"),"x"===e.key&&e.ctrlKey&&navMenu.classList.toggle("show")})</script><style>.nav{position:fixed;top:0;right:0;z-index:200;background-color:#3f6388;padding:0;display:block;font-family:Inter}.nav-toggle{background-color:#3f6388;border:none;padding:8px;padding-right:24px;font-size:18px;cursor:pointer}.nav-menu{position:fixed;right:0;top:48px;background-color:#3f6388;padding:10px;width:300px;height:100vh;overflow-y:auto;display:none}.nav-menu ul{list-style:none;margin:0;padding:0}.nav-menu li{margin-bottom:10px}.nav-menu a{color:#fff;text-decoration:none;font-size:18px;font-weight:700;text-align:center;padding:10px 10px;display:block}.nav-menu a:hover{color:#fff;background-color:#000}.nav-title{font-size:18px;margin-left:10px;color:#fff}.nav-brand{font-size:24px;font-weight:700;margin:10px 20px;color:#fff}.nav-menu.show{display:block}</style><script src="/julia_book/libs/clipboard.min.js"></script><script>!function(){for(var t=document.getElementsByTagName("pre"),e=0;e<t.length;e++){var n=t[e].children[0].className;if(n.startsWith("language-")||n.endsWith(" hljs")){var o=document.createElement("button");o.className="copy-button",o.textContent="Copy",t[e].appendChild(o)}}var r=new Clipboard(".copy-button",{target:function(t){return t.previousElementSibling}});r.on("success",function(t){t.clearSelection(),t.trigger.textContent="copied!",window.setTimeout(function(){t.trigger.textContent="copy"},2e3)}),r.on("error",function(t){t.trigger.textContent='Press "Ctrl + C" to copy',window.setTimeout(function(){t.trigger.textContent="Copy"},5e3)})}()</script><style>@media print{.franklin-content{box-sizing:border-box}.jumbotron{padding-right:60px!important}.jumbotron,.name_format,.phd_format{color:#000!important}.name_format a{color:#3f6388}.hide_tab details[open] p,.hide_tab>details[open]>summary,.sign_output,.tab_code_links,nav{display:none!important}.bar_top,.bar_top .modalButton,.copy-button,.footn,.left_bar,.left_bar_mobile,.nav-item,.navbar,footer,nav{display:none!important}.tab_wrapper{display:flex!important;flex-wrap:wrap;gap:1cm;width:100%;padding-top:20px;padding-bottom:20px}.tabcontent{display:block!important;margin-bottom:2em;page-break-inside:avoid;border:2px solid #3f6388!important}.print-tab-title{font-weight:700;font-size:100%;padding:0 0;padding-left:.35cm;color:#000;text-transform:uppercase;display:block!important}.code_in_modal,.output_in_modal{width:100%;height:auto!important;overflow:visible;border:none!important}.code_NoFormat pre,.mixed_output_NoFormat pre{border:none!important}.code_NoFormat,.code_in_modal,.julia_repl_NoFormat,.mixed_output_NoFormat,.mixed_output_inline{margin:0!important;padding:0!important}.code_NoFormat,.julia_repl_NoFormat,.mixed_output_NoFormat{padding-left:.35cm!important;padding-top:.15cm!important}.output_in_modal{margin-top:12px!important;border-top:2px solid #20c679!important}.code_NoFormat,.code_in_modal{border-top:2px solid #3f6388}#remarkCodeContent{height:.1px!important;visibility:hidden!important}}</style><script>function printAllTabs(){const t=document.querySelectorAll(".tablink");document.querySelectorAll(".tabcontent").forEach((e,n)=>{const r=t[n].textContent.trim();if(!e.querySelector(".print-tab-title")){const t=document.createElement("div");t.className="print-tab-title",t.textContent=r,e.insertBefore(t,e.firstChild)}});for(var e=document.getElementsByTagName("a"),n=0;n<e.length;n++)e[n].removeAttribute("href"),e[n].style.textDecoration="none"}window.matchMedia("print").addListener(t=>{if(t.matches)printAllTabs();else{document.querySelectorAll(".tabcontent").forEach(t=>{const e=t.querySelector(".print-tab-title");e&&t.removeChild(e)})}})</script>