<!-- 
#################################################
# HEAD - FOR ALL PAGES
#################################################
 --><!doctype html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name="author" content="Martin Alfaro"><script>function applySavedTheme(){"enabled"===localStorage.getItem("darkMode")&&document.documentElement.classList.add("dark-mode")}applySavedTheme()</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Cormorant+SC:wght@300;400;600;700&family=Inter:wght@300..900&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet"><link rel="stylesheet" href="/julia_book/libs/katex/katex.min.css"><link rel="stylesheet" href="/julia_book/libs/highlight/styles/vs_myversion.css"><link rel="stylesheet" href="/julia_book/css/bootstrap.min.css"><style>.section-bg-color{background-color:rgba(63,99,136,.07)}footer a{color:#6495ed}header{margin-top:0!important}header .jumbotron{background-image:linear-gradient(to right,#000,#000 10%,#3f6388 55%,#3f6388);background-repeat:no-repeat;background-size:100%}</style><link rel="stylesheet" href="/julia_book/css/custom.css"><title>11f. Parallelization in Practice - Julia Book - Martin Alfaro</title><link rel="icon" type="image/png" href="/julia_book/assets/icons/favicon.ico"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-K96JNP7PKB"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K96JNP7PKB")</script><body id="page-top"><!-- 
#################################################
# FOR EACH SPECIFIC PAGE
#################################################
 --><style>html{scroll-behavior:auto}.bar_top,.jumbotron,.left_bar,.nav-item,.navbar,footer{font-size:16px;font-family:"Open Sans"}.franklin-content{font-size:17px;font-family:"Open Sans"}h1{font-family:Inter,"Open Sans";font-weight:600}h1{padding-top:.1em;font-size:210%!important;font-weight:700;text-align:center}.phd_format{color:#fff;text-decoration:none;font-size:90%;text-align:center;margin-top:-.2em;margin-bottom:-.89em}.name_format{padding-top:.35em;text-decoration:none;font-size:160%}.name_format a{color:#fff}.name_format a:hover{color:#d4d4d4;color:#d6e3f0}.franklin-content{background-color:#d9e0e7}.franklin-content{margin:0;width:100%;height:100%;justify-content:center;text-align:justify;text-justify:inter-word;line-height:1.65}.jumbotron{margin-bottom:0;padding-top:42px;padding-bottom:2em;border-bottom:#000 solid 1px;border-radius:0}.franklin-content,.jumbotron{padding-left:160px}footer{background-image:linear-gradient(to right,#23374b,#000 50%,#3f6388);background-color:#3f6388;width:calc(100%+10px);margin-left:-10px;padding-left:10px}h2{text-transform:uppercase;font-size:160%;text-align:center;text-decoration:underline;padding-bottom:.5em;font-weight:700}h3{text-align:left;text-transform:uppercase;text-decoration:underline;padding-bottom:0;padding-top:.5em;font-size:120%;font-weight:600}h4 a{font-weight:800!important}h4{text-align:left;color:#3a6c9e;text-decoration:underline;padding-bottom:0;padding-top:.5em;font-weight:800!important;text-transform:uppercase;font-size:120%}h5,h6{text-indent:0;line-height:1.2em;padding-top:.99em;padding-bottom:-0em}section{margin-left:0;padding-left:1%;padding-right:1%;padding-top:1.5%;padding-bottom:1%;text-align:justify;text-justify:inter-word;line-height:1.65;text-indent:0;font-size:100%;color:#000}section h1{text-indent:0;margin-left:0}section h2{text-indent:0;margin-bottom:0}.franklin-content ul{margin-left:0;margin-top:-.6em;line-height:1.15}.franklin-content ul li p{margin-left:0;margin-bottom:.6em;line-height:1.35;text-indent:0}.franklin-content ol li{margin-left:2em;line-height:1.15}ul ::marker{color:#49739d}ol ::marker{color:#5381af;font-weight:700}a.anchor{display:block;position:relative;top:-150px;visibility:hidden}section a{color:#3e79b4;text-decoration:underline;font-weight:500}section a:hover{color:rgba(62,121,180,.699);text-decoration:underline}</style><style>:target{scroll-margin-top:40px}.own-anchors a{scroll-margin-top:4em}</style><div class="left_bar" style="color:#fff"><span><img src="/julia_book/assets/pics_html/julia_logo-dark.svg" alt="pic" style="padding:12px;padding-right:28px;padding-top:44px" width="160px" height="auto"></span><link href="/julia_book/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/julia_book/pagefind/pagefind-ui.js"></script><ul><li style="text-transform:uppercase"><a href="/julia_book/index.html"><img src="/julia_book/assets/icons/home.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Home</a></li><li style="text-transform:uppercase"><a href="/julia_book/list_posts/"><img src="/julia_book/assets/icons/books03.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Chapters</a></li><li><div style="text-indent:0"><button class="modalButton" style="text-transform:uppercase"><img src="/julia_book/assets/icons/keyboard01.png" style="width:20%;height:auto;opacity:.9;margin-bottom:-26px;margin-left:-30px;padding-right:4px"> <span style="margin-left:-.2em">Notation &<div style="margin-left:-1.2em;margin-top:-3em">Hotkeys</div></span></button><div class="kbd_shortcuts"><div class="modal" id="kbdmodal_bar"><div class="modal-content"><div class="modal-header"><h2>NOTATION</h2></div><div class="modal-body" style="height:auto">Generic expressions are represented by <b>&lt;something&gt;</b> (e.g., <code>&lt;function&gt;</code> or <code>&lt;operator&gt;</code>). This is just notation, and the symbols <code>&lt;</code> and <code>&gt;</code> should not be misconstrued as Julia's syntax.</div><div class="modal-header"><h2>PAGE LAYOUT</h2></div><div class="modal-body">If you want to adjust the size of the font, <b>zoom in or out on pages</b> by respectively using <kbd>Ctrl</kbd>+<kbd>+</kbd> and <kbd>Ctrl</kbd>+<kbd>-</kbd>. The layout will adjust automatically.<br><span class="brmine"></span></div><div class="modal-header"><h2>LINKS TO SECTIONS</h2></div><div class="modal-body">To quickly share a link to a specific section, simply hover over the title and click on it. The link will be automatically copied to your clipboard, ready to be pasted. <span class="brmine"></span></div><div class="modal-header"><h2>KEYBOARD SHORTCUTS</h2></div><div class="modal-body"><style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:#000;border-style:solid;border-width:1px;overflow:hidden;padding:10px 12px;word-break:normal}.tg th{border-color:#000;border-style:solid;border-width:1px;font-weight:400;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-80zn{background-color:rgba(63,99,136,.2);border-color:#fff;font-weight:700;text-align:center;vertical-align:top}.tg .tg-esg4{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:right;vertical-align:top}.tg .tg-8jgo{border-color:#fff;text-align:left;vertical-align:top}.tg .tg-ofj5{border-color:#fff;text-align:center;vertical-align:top}</style><table class="tg" style="margin-left:auto;margin-right:auto"><thead><tr><th class="tg-80zn">Action</th><th class="tg-80zn">Keyboard Shortcut</th></tr></thead><tbody><tr><td class="tg-8jgo">Previous Section</td><td class="tg-ofj5"><kbd>Ctrl + ðŸ ˜</kbd></td></tr><tr><td class="tg-8jgo">Next Section</td><td class="tg-ofj5"><kbd>Ctrl + ðŸ š</kbd></td></tr><tr><td class="tg-8jgo">List of Subsections</td><td class="tg-ofj5"><kbd>Ctrl + x</kbd></td></tr><tr><td class="tg-8jgo">Close Any Popped Up Window (like this one)</td><td class="tg-ofj5"><kbd>Esc</kbd></td></tr><tr><td class="tg-8jgo">Open All Codes and Outputs in a Post</td><td class="tg-ofj5"><kbd>Alt + ðŸ ›</kbd></td></tr><tr><td class="tg-8jgo">Close All Codes and Outputs in a Post</td><td class="tg-ofj5"><kbd>Alt + ðŸ ™</kbd></td></tr></tbody></table><span class="brmine"></span></div><div class="modal-header"><h2>TIME MEASUREMENT</h2></div><div class="modal-body">When benchmarking, the equivalence of time measures is as follows.<br><br><style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:#000;border-style:solid;border-width:1px;overflow:hidden;padding:10px 5px;word-break:normal}.tg th{border-color:#000;border-style:solid;border-width:1px;font-weight:400;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-80zn{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:left;vertical-align:top}.tg .tg-esg4{background-color:#ebebeb;border-color:#fff;font-weight:700;text-align:right;vertical-align:top}.tg .tg-8jgo{border-color:#fff;text-align:left;vertical-align:top}.tg .tg-ofj5{border-color:#fff;text-align:center;vertical-align:top}</style><table class="tg" style="margin-left:auto;margin-right:auto"><thead><tr><th class="tg-80zn">Unit</th><th class="tg-80zn">Acronym</th><th class="tg-80zn">Measure in Seconds</th></tr></thead><tbody><tr><td class="tg-8jgo">Seconds</td><td class="tg-ofj5">s</td><td class="tg-ofj5">1</td></tr><tr><td class="tg-8jgo">Milliseconds</td><td class="tg-ofj5">ms</td><td class="tg-ofj5">10<sup>-3</sup></td></tr><tr><td class="tg-8jgo">Microseconds</td><td class="tg-ofj5">Î¼s</td><td class="tg-ofj5">10<sup>-6</sup></td></tr><tr><td class="tg-8jgo">Nanoseconds</td><td class="tg-ofj5">ns</td><td class="tg-ofj5">10<sup>-9</sup></td></tr></tbody></table></div></div><style>.left_bar .kbd_shortcuts{color:#000;font-size:16px;line-height:1.55;list-style-type:none;position:relative}.left_bar .kbd_shortcuts kbd{font-size:14px}.left_bar .kbd_shortcuts .modal-content{position:relative;width:1200px;max-width:90%;height:max-content;max-height:90%;margin-top:55px;background-color:#cfdae4;overflow:auto}.left_bar .kbd_shortcuts .modal-body{margin:0;padding-bottom:12px;text-align:justify;padding-top:8px;padding-bottom:2px;overflow:visible;height:100%}.left_bar .kbd_shortcuts .modal-header{padding:0;color:#fff;width:100%}.left_bar .kbd_shortcuts .modal-header h2{padding-top:8px;font-size:20px;font-weight:700;width:100%;text-align:center;color:#fff;background-color:#3f6388}.left_bar .modalButton{border:none;box-shadow:none;width:auto;padding:0;background-color:transparent;color:#fff;margin:0}.left_bar .brmine{display:block;margin-bottom:.5em}</style></div></div></div></li><li style="text-transform:uppercase"><a href="/julia_book/links/"><img src="/julia_book/assets/icons/links.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> Links</a></li><li><a href="/julia_book/assets/pdf/juliaBook_Alfaro.pdf"><img src="/julia_book/assets/icons/icon_pdf.png" style="width:15%;height:auto;opacity:.9;padding-bottom:5px"> BOOK in PDF</a></li><li><h3 style="font-weight:400;font-size:14px;padding-top:2em;margin-bottom:-.5em;text-decoration:none">Dark Mode</h3><label class="switch"><input type="checkbox" id="toggleStyles"> <span class="slider round"></span></label></li></ul><div class="personal_website"><a href="https://alfaromartino.github.io"><img src="/julia_book/assets/icons/personal.png" style="width:18%;height:auto;opacity:.9;margin-bottom:-14px;padding-right:4px"> Personal<div style="margin-left:calc(30px + 2px);margin-top:-.5em">Website</div></a></div></div><style>@media (max-width:850px),(max-height:600px){.left_bar{display:none}}.left_bar{z-index:200;background-image:linear-gradient(to left bottom,#000,#000 10%,#3f6388 80%,#3f6388);position:fixed;font-family:Inter,"Open Sans";height:100%;top:0;left:0;font-size:20px;width:160px}.left_bar ul{list-style-type:none;float:left;font-size:80%;position:relative;padding-left:.8em;padding-top:40px;line-height:4.25em}.left_bar .personal_website a,.left_bar li a{color:#fff}.left_bar .personal_website a:hover,.left_bar a:hover{color:#a09f9f}.left_bar .personal_website{position:absolute;bottom:0;padding-bottom:1em;left:12px;font-size:20px;font-family:"Cormorant SC";font-weight:700}</style><style>.switch{position:relative;display:inline-block;width:30px;height:17px}.switch input{display:none}.slider{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#ccc;transition:.4s}.slider:before{position:absolute;content:"";height:13px;width:13px;left:2px;bottom:2px;background-color:#fff;transition:.4s}input:checked+.slider{background-color:#000}input:checked+.slider:before{transform:translateX(13px)}.slider.round{border-radius:17px}.slider.round:before{border-radius:50%}html.dark-mode{background-color:#030911!important}html.dark-mode .franklin-content,html.dark-mode .modal-body{background-color:#030911!important}html.dark-mode .franklin-content section,html.dark-mode .index_container,html.dark-mode .modal-content{color:#ebf4fc!important}html.dark-mode .index_container,html.dark-mode .index_container h1{background-color:#030d18!important}html.dark-mode .index_container ul>li{color:#ebf4fc!important}html.dark-mode .index_container a{color:#588cc0}html.dark-mode .index_container a:hover,html.dark-mode h2:hover,html.dark-mode section a:hover{color:#bed5ec}html.dark-mode .multiple_pics{background-color:#4b6d92}html.dark-mode .multiple_pics h2{color:#fff!important}html.dark-mode .note,html.dark-mode .warning{color:#000}html.dark-mode .code_box,html.dark-mode .code_in_modal,html.dark-mode .img_output_in_modal,html.dark-mode .output_in_modal{border-width:1px;border-style:solid;border-color:rgba(0,44,82,.99)}html.dark-mode .tab_wrapper .tab_code_links .tablink.active{background-color:rgba(94,140,185,.95)}html.dark-mode .tab_wrapper .tab_code_links .tablink:hover{background-color:rgba(94,140,185,.95)}html.dark-mode .bar_top,html.dark-mode .nav-menu.show,html.dark-mode nav .nav-toggle{background-image:linear-gradient(to top,#122030,#122030 60%)!important}html.dark-mode .bar_top .modal-body,html.dark-mode .bar_top .modal-content,html.dark-mode .bar_top .modal-header{background-image:linear-gradient(to top,#122030,#122030 60%)!important}html.dark-mode header .jumbotron{background-image:linear-gradient(to bottom,#122030,#122030 50%)!important}html.dark-mode .left_bar{background-image:linear-gradient(to left bottom,#122030,#122030 10%)}html.dark-mode footer{background-image:linear-gradient(to right,#122030,#000 10%)!important;border-top:1px solid rgba(0,44,82,.99);background-color:rgba(63,99,136,.3);width:calc(100%+10px);margin-left:0;padding-left:10px}html.dark-mode .left_bar .kbd_shortcuts .modal-content{background-color:#000!important}</style><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("toggleStyles"),t=document.documentElement;"enabled"===localStorage.getItem("darkMode")&&(e.checked=!0),e.addEventListener("change",function(){this.checked?(t.classList.add("dark-mode"),localStorage.setItem("darkMode","enabled")):(t.classList.remove("dark-mode"),localStorage.setItem("darkMode","disabled"))})})</script><header class="text-white text-center"><div class="jumbotron jumbotron-fluid container-fluid bg-primary"><h1><i>11f.</i> Parallelization in Practice</h1><div class="lead"></div><div class="name_format"><a href="https://alfaromartino.github.io/" target="_blank" rel="noopener noreferrer">Martin Alfaro</a></div><div class="phd_format">PhD in Economics</div></div></header><link href="https://fonts.cdnfonts.com/css/cascadia-mono" rel="stylesheet"><style>pre{position:relative;overflow:hidden}code{background-color:#d1d9e0;color:#000;text-indent:0;padding-top:.1em;padding-bottom:.1em;padding-left:.3em;padding-right:.3em;vertical-align:.05em;border:1px solid #001029;overflow:hidden}.julia_repl_NoFormat code,.mixed_output_NoFormat code{background-color:#527868;color:#dcdcdc;border:1px solid #527868}.copy-button{cursor:pointer;border:none;font-size:12px;text-transform:lowercase;font-weight:500;padding:2px 10px 2px;background-color:#3f6388;position:absolute;top:0;right:12px;text-align:center;color:#fff;margin-top:0;z-index:1}.copy-button:hover{outline:0;background-color:#5483b3}.copy-button:focus{outline:0;background-color:#324e6b}.julia_line{color:#20c679!important;font-weight:700;display:inline;font-size:100%}.julia_repl_NoFormat{font-size:87%}.julia_repl_NoFormat .julia_line,.julia_repl_NoFormat code{font-size:100%}.mixed_output_NoFormat{font-size:87%}.mixed_output_NoFormat .julia_line,.mixed_output_NoFormat code,.mixed_output_NoFormat pre{font-size:100%}.akin_to_pre{white-space:pre-wrap;font-family:Consolas,monospace}.julia_repl_NoFormat{font-family:Consolas,monospace;color:#dcdcdc;border:none;background-color:#013b1f;margin:0;padding:0}.julia_repl_NoFormat .akin_to_pre{line-height:1.35;color:#dcdcdc;margin:0;padding:0}.franklin_output_NoFormat{font-family:Consolas,monospace;margin:0;padding:0;background-color:#013b1f}.franklin_output_NoFormat pre{margin:0;padding:0;line-height:1.35;background-color:#013b1f}.franklin_output_NoFormat pre code{margin:0!important;padding:0!important;border:none;background-color:#013b1f}.mixed_output_NoFormat{font-family:Consolas,monospace;color:#dcdcdc;border:none;background-color:#013b1f;margin:0;padding:0}.mixed_output_NoFormat pre{line-height:1.35;color:#dcdcdc;margin:0;padding:0}.mixed_output_NoFormat pre code{margin:0!important;padding:0!important;border:none;background-color:#013b1f}.mixed_output_inline{color:#dcdcdc;font-family:Consolas,monospace;background-color:#013b1f;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.output_box{margin:0;padding:0}.output_box details>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6b4b;cursor:pointer;color:#fff;box-shadow:3px 3px 4px #000;text-indent:0}.output_box details[open]>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6b4b;border:#282c34;border-width:1px;border-style:solid}.output_box{padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:1em}.code_NoFormat{line-height:1.45;margin:0;padding:0;background-color:#001029}.code_NoFormat pre{margin:0;padding:0;background-color:#001029}.code_NoFormat pre code{font-family:"Cascadia Mono",monospace;margin:0!important;padding:0!important;border:none;background-color:#001029}.code_NoFormat p{padding:0;margin:0}.code_inline{background-color:#001029;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.code_box{margin:0;padding:0}.code_box details>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6388;cursor:pointer;color:#fff;box-shadow:3px 3px 4px #000;text-indent:0}.code_box details[open]>summary{width:max-content;max-width:90%;padding-left:10px;padding-right:10px;background-color:#3f6388;border:#282c34;border-width:1px;border-style:solid}.code_box{padding-top:0;padding-bottom:0;margin-top:0;margin-bottom:1em}.hide_tab{padding-top:0;padding-bottom:0;margin-top:0;margin-bottom:1em}.hide_tab>details>summary{max-width:100%;min-width:30px;width:fit-content;padding-left:11px;padding-right:0;padding-bottom:0;background-color:#3f6388;cursor:pointer;color:#fff;text-indent:0;border:#282c34;border-width:1px;border-style:solid}.hide_tab>details[open]>summary .closed_text{display:none}.hide_tab>details>summary .closed_text{padding-left:1em;padding-right:1em;margin-left:.25em;display:inline-block;border-left:#282c34;border-width:1px;border-style:solid;border-bottom:none;border-top:none;border-right:none}.hide_tab>details[open]>summary{position:absolute;width:35px;max-width:90%;height:1.94em;padding-bottom:0;padding-top:3px;padding-left:12px;padding-right:5px;background-color:#3f6388;border:#282c34;border-width:1px;border-style:solid;border-bottom:none}.tab_wrapper{width:100%;display:inline-block}.tab_wrapper .tab_code_links{background-color:#001029}.tab_wrapper .tab_code_links .tablink{background-color:#3f6388;color:#fff;float:left;border:1px solid #000;outline:0;cursor:pointer;padding:2px 20px;width:max-content;height:auto}.tab_wrapper .tab_code_links .tablink.first_tab{padding-left:54px}.tab_wrapper .tab_code_links .tablink.active{font-weight:500;background-color:rgba(82,127,173,.836)}.tab_wrapper .tab_code_links .tablink:hover{background-color:rgba(82,127,173,.836)}.tab_wrapper .tabcontent{background-color:#001029;display:none;width:100%;float:left;margin:0;padding:0}.tab_wrapper .tabcontent.active{display:block}.code_in_modal{background-color:#001029;padding-left:1em;padding-top:.5em;padding-bottom:1em;margin-top:0;margin-bottom:0}.output_in_modal{background-color:#013b1f}.img_output,.img_output_in_modal{text-indent:0;margin:0;padding:0;background-color:#181818}.img_output_in_modal_old,.img_output_old{text-indent:0;margin:0;padding:0;background-color:#1e1e1e}.sign_output{color:#fff;width:100%;max-width:100%;height:auto;padding-bottom:0;padding-top:0;padding-left:12px;padding-right:12px;background-color:#3f6b4b;border:#282c34;border-width:1px;border-style:solid;margin-bottom:0;padding-top:0}.outputmodal_container{padding:0;margin:0}</style><style>.gif_output_in_modal{text-indent:0;margin:0;padding:0;background-color:#181818}.gif_output{position:relative;display:inline-block;cursor:pointer;margin:0;padding:0;max-width:100%}.gif-wrapper{display:block;visibility:hidden;margin:0;padding:0;max-width:100%}.gif-wrapper.playing{visibility:visible}.play-overlay{position:absolute;top:0;left:0;right:0;bottom:0;background-color:#181818;background-color:#000;display:flex;justify-content:center;align-items:center}.play-overlay.hidden{background:0 0}.play-button{background:0 0;border:none;color:#fff;cursor:pointer;padding:0;transform:scale(.5);transition:background .3s}.play-overlay.hidden .play-button{display:none}</style><script>function setMaxHeight(){const e=document.querySelectorAll(".gif-wrapper");let t=0;e.forEach(e=>{const o=e.offsetHeight;o>t&&(t=o)}),e.forEach(e=>{e.style.height=`${t}px`,e.style.width="auto"})}document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".gif_output");let t=0;e.forEach(o=>{const n=o.querySelector(".gif-wrapper"),c=o.querySelector(".play-overlay");let l=!1;n.onload=function(){t++,t===e.length&&setMaxHeight()},o.addEventListener("click",function(){l?(n.classList.remove("playing"),c.classList.remove("hidden"),l=!1):(n.classList.add("playing"),c.classList.add("hidden"),l=!0)})})})</script><div class="bar_top"><ul><li><div style="text-indent:0"><button class="modalButton" id="openSearch" style="background-color:transparent;color:#fff;display:block;margin-bottom:-2px"><img src="/julia_book/assets/icons/search_icon.png" style="width:auto;height:30px;opacity:.9;padding-bottom:5px;margin-left:0;padding-right:0"> <span>Search</span></button></div><div class="searchBar" id="searchModal" style="display:none"><div class="modal"><div class="modal-content"><div class="modal-header"><h2>Search</h2></div><div class="modal-body"><div id="search_modal_container"></div></div></div></div></div></li></ul></div><style>.bar_top{padding-left:160px}.bar_top{background-image:linear-gradient(to right,#000,#000 10%,#3f6388 55%,#3f6388);position:fixed;width:100%;height:48px;top:0;left:0;padding:8px 0 10px 0;font-size:110%;z-index:125;font-family:Inter}.bar_top a:hover{color:#a09f9f}.bar_top>ul{list-style-type:none;float:left;position:relative;bottom:0;padding-left:1%;left:160px}.bar_top li a{color:#fff}.bar_top .modal{background-color:transparent;margin-top:48px;padding-left:1%;margin-left:0;width:100%;height:100%;overflow:auto;position:fixed}.bar_top .modal-content{position:relative;width:1200px;max-width:90%;height:max-content;max-height:90%;background-color:#000;margin:auto;padding:8px;margin-left:160px;-webkit-animation-name:none;animation-name:none}.bar_top .modal-header{background-color:#000;color:#fff}.bar_top .modal-body{color:#649dd6}.bar_top .modal-body .row{display:flex}.bar_top .modal-body .row .column{flex:1}.bar_top .modal-body .row h3{padding-bottom:.5em}.bar_top .modal-body .row ul li{line-height:1}.bar_top .modal-body .row ul li ul{list-style-type:none;margin:0;padding:0;padding-top:.5em;padding-bottom:.4em;line-height:1}.bar_top .modal-body .row ul li ul li{line-height:1}.bar_top .modal-body .row li{line-height:1;list-style-type:none;float:center;text-indent:-20px;padding-left:22px;position:relative}.bar_top .modal-body .row .column{text-align:center}.bar_top .modal-body .row .column h3{text-align:center}.bar_top .modal-body .row .column ul{text-align:left;margin-left:auto;margin-right:auto;list-style-position:inside;line-height:.55em}.bar_top .modalButton{border:none;margin-bottom:24px;box-shadow:none}.bar_top .modalClose{font-size:0px}</style><style>.footn{position:relative;display:inline-block;margin-left:-.6em;margin-right:0;color:#2669dd;text-decoration:underline}.supr{vertical-align:80%;font-size:75%;line-height:1}.footn .footn_text{font-size:125%;visibility:hidden;text-align:justify;text-justify:inter-word;text-indent:0;line-height:1.5;background-color:#282c34;color:#e0e4eb;border-radius:6px;padding:5px 12px 5px 12px;position:absolute;z-index:1;bottom:100%;right:0}.footn .footn_text.left{left:0;width:max-content;max-width:500px}.footn .footn_text.right{right:0;width:max-content;max-width:500px}.footn:hover .footn_text{visibility:visible}.footn a{color:#7b9fdd}.footn a:hover{color:#a1b6dbb2}</style><script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js"></script><script>$(document).ready(function(){$(".footn.supr").hover(function(){var t=$(this).find(".footn_text"),e=$(this).closest("p"),o=e.width(),s=t.offset().left-e.offset().left>o/2;t.removeClass("left right"),s?t.addClass("right"):t.addClass("left"),t.addClass("hovering")},function(){$(this).find(".footn_text").removeClass("hovering"),$(this).find(".footn_text").removeClass("left right")})})</script><style>@media (max-width:768px){.footn .footn_text.left{left:0;width:max-content;max-width:200px}.footn .footn_text.right{right:0;width:max-content;max-width:200px}}</style><style>@media (max-width:850px){.jumbotron{font-size:90%!important}.franklin-content{font-size:100%!important}.franklin-content{padding-left:1%;padding-right:1%}.franklin-content .container{max-width:100%!important}.index_container,.index_container section{font-size:100%}.index_container{padding-left:1%;padding-right:1%}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}.home_container section{font-size:100%;line-height:1.55em}.home_container ul li{padding-right:1%;padding-left:0}.home_container ul{padding-right:0;padding-left:0}.home_container .row li{padding-left:0;padding-bottom:1.55em;margin-left:0}.home_container .bullets_nomarker ul li p{line-height:1.55!important}.col-lg-.mx-auto{overflow:auto!important}.jumbotron{padding-left:60px!important;padding-right:1%!important;padding-top:0;margin-top:0}.modal{padding:2px!important}.bullets ol,.itemNoSpace ol{padding:4px}.bullets ul li,.itemNoSpace ul li{padding-right:5%;padding-left:0;margin-left:0}.bullets ul li p,.itemNoSpace ul li p{line-height:1.65}}@media (max-height:600px){.jumbotron{font-size:90%!important}.franklin-content{font-size:100%!important}.franklin-content .container{max-width:100%!important}.index_container,.index_container section{font-size:100%}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}.index_container{padding-left:1%;padding-right:1%}.col-lg-.mx-auto{overflow:auto!important}.jumbotron{padding-left:60px!important;padding-right:1%!important;padding-top:0;margin-top:0}.franklin-content{padding-left:0!important}.modal{padding:2px!important}.bullets ol,.itemNoSpace ol{padding:6px}.bullets ul li,.itemNoSpace ul li{padding-right:5%;padding-left:0;margin-left:0}.bullets ul li p,.itemNoSpace ul li p{line-height:1.55}.index_container ul li{padding-right:5%;padding-left:0}.index_container ul{padding-right:0;padding-left:5%}}</style><div class="left_bar_mobile" style="color:#fff"><ul><li><a href="/julia_book/index.html"><img src="/julia_book/assets/icons/home.png" style="width:15%;height:auto;opacity:.9;padding-bottom:0"> HOME</a></li><li><a href="/julia_book/list_posts/"><img src="/julia_book/assets/icons/books03.png" style="width:15%;height:auto;opacity:.9;padding-bottom:0"> CHAPTERS</a></li><li><div class="dark-mode-mobile"><label class="switch"><input type="checkbox" class="toggleMobile"> <span class="slider round"></span></label></div></li></ul></div><style>@media (min-width:850px),(min-height:600px){.left_bar_mobile{display:none}}@media (max-width:850px),(max-height:600px){.left_bar_mobile{display:block}.left_bar_mobile img{display:none}.left_bar_mobile{z-index:200;background-image:none;position:absolute;font-family:Inter;height:160px!important;top:0;left:0;font-size:85% width : 60px}.left_bar_mobile ul{list-style-type:none;float:left;font-size:100%;position:relative;padding-left:.4em;padding-top:.2em;line-height:2em!important;height:100%;top:0;width:60px;display:flex;flex-direction:column;justify-content:space-around}.left_bar_mobile li{flex:1}.left_bar_mobile li a{color:#fff}.left_bar_mobile a:hover{color:#a09f9f}.dark-mode-mobile{position:relative;bottom:0;margin-top:auto}.dark-mode-mobile .switch{width:40px;height:20px}.dark-mode-mobile .slider:before{height:15px;width:15px}.dark-mode-mobile input:checked+.slider:before{transform:translateX(20px)}@media (max-width:850px),(max-height:600px){h2{font-size:140%;padding-top:1em}h1{font-size:180%;padding-top:.5em;padding-bottom:0}}}</style><style>@media (max-width:850px),(max-height:600px){.lead{display:none}.bar_top,.py-1 .container .center-text,nav{display:none!important}.jumbotron{padding-left:80px;padding-right:.1%!important;padding-top:0;margin-top:0}}</style><style>@media (min-width:850px),(min-height:600px){.dark-mode-mobile{visibility:hidden}}@media (max-width:850px),(max-height:600px){.dark-mode-mobile{visibility:visible}}</style><script>document.querySelector(".toggleMobile").addEventListener("change",function(){const e=document.documentElement;this.checked?(e.classList.add("dark-mode"),localStorage.setItem("darkMode","enabled")):(e.classList.remove("dark-mode"),localStorage.setItem("darkMode","disabled"))}),window.addEventListener("load",function(){const e=document.documentElement;"enabled"===localStorage.getItem("darkMode")?(document.querySelector(".toggleMobile").checked=!0,e.classList.add("dark-mode")):document.querySelector(".toggleMobile").checked=!1})</script><div class="franklin-content"><section id="introduction" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Introduction</h2><p></p><p>So far, we&#39;ve explored two macros for parallelization: <code>@spawn</code> and <code>@threads</code>. The macro <code>@spawn</code> provides granular control over the parallelization process, letting users explicitly define the tasks to be executed concurrently. In contrast, <code>@threads</code> offers a simpler approach for parallelizing for-loops, where iterations are automatically partitioned into tasks, according to the number of available threads. Furthermore, we&#39;ve pointed out that, due to inherent dependencies between computations, not all workloads are equally amenable to parallelization. In particular, a naive approach to parallelization can lead to severe issues.</p><p>Essentially, our discussions have largely focused on the <em>syntax</em> and <em>work distribution</em> of parallelization approaches. Yet, we have to address how to apply multithreading in real scenarios. Furthermore, given the possibility of dependencies between computations, <em>how</em> to parallelize is only part of the challenge: knowing <em>when</em> to parallelize is equally important.</p><p>This section and the next one aim to bridge this gap, providing practical guidance on implementing multithreading. We begin by highlighting the advantages of coarse-grained parallelization over fine-grained parallelization. By dividing the workload into a small number of large tasks, coarse-grained parallelization reduces the scheduling overhead from managing numerous lightweight tasks.</p><p>After this, we revisit the parallelization of for-loops, this time using <code>@spawn</code>. In particular, leveraging the additional control that <code>@spawn</code> provides over task creation, we&#39;ll demonstrate how to apply multithreading in the presence of a ubiquitous type of dependency: reductions.</p><p>We conclude by showing a performance issue arising with multithreading, known as false sharing. While this doesn&#39;t affect the correctness the result, it can significantly slow down computations if not addressed.</p><p></p></div></div></div></section><section id="better_to_parallelize_at_the_top" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Better To Parallelize at The Top</h2><p></p><p>Given the overhead involved in multithreading, there&#39;s an inherent trade-off between creating new tasks and fully utilizing machine resources. This is why we must always consider whether parallelization is worthwhile in the first place. For instance, when it comes to operations over collections, multithreading is only justified if the collections have enough elements to offset the associated overhead. Otherwise, single-threaded approaches will consistently outperform parallelized ones.</p><p>In case multithreading is deemed beneficial, we immediately face another decision: at what level code should be parallelized. Next, we&#39;ll demonstrate that <strong>parallelism at the highest possible level is preferable, compared to multithreading individual operations</strong>. By adopting this strategy, we minimize the overhead of task creation.</p><p>Note that the level of parallelization is always constrained by the degree of dependency between operations. Hence, our qualification of highest <strong>possible</strong> level. For instance, in problems requiring strictly serial computation, the best we can achieve is parallelization within each individual step.</p><p>To illustrate, let&#39;s consider a for-loop where each iteration needs to sequentially compute three operations.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Julia's Default</button> <button class="tablink" data-id="">Parallelization at The Highest Level Possible</button> <button class="tablink" data-id="">Each Operation Parallelized</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function all_steps&#40;a&#41; 
   y      &#61; step1&#40;a&#41;
   z      &#61; step2&#40;y&#41;
   output &#61; step3&#40;z&#41;

   return output
end

function foo&#40;x&#41;
   output &#61; similar&#40;x&#41;

   for i in eachindex&#40;output&#41;
      output&#91;i&#93; &#61; all_steps&#40;x&#91;i&#93;&#41;
   end

   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  5.206 Î¼s (3 allocations: 7.883 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_large&#41;</code><br><pre><code class="plaintext code-output">  537.663 Î¼s (3 allocations: 781.320 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function all_steps&#40;a&#41; 
   y      &#61; step1&#40;a&#41;
   z      &#61; step2&#40;y&#41;
   output &#61; step3&#40;z&#41;

   return output
end

function foo&#40;x&#41;
   output &#61; similar&#40;x&#41;

   @threads for i in eachindex&#40;output&#41;
      output&#91;i&#93; &#61; all_steps&#40;x&#91;i&#93;&#41;
   end

   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  13.667 Î¼s (125 allocations: 20.508 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_large&#41;</code><br><pre><code class="plaintext code-output">  71.050 Î¼s (125 allocations: 793.945 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">step1&#40;a&#41; &#61; a ^ 2
step2&#40;a&#41; &#61; sqrt&#40;a&#41;
step3&#40;a&#41; &#61; log&#40;a &#43; 1&#41;

function parallel_step&#40;f, x&#41;
   output &#61; similar&#40;x&#41;

   @threads for i in eachindex&#40;output&#41;      
      output&#91;i&#93; &#61; f&#40;x&#91;i&#93;&#41;
   end

   return output
end

function foo&#40;x&#41;
   y      &#61; parallel_step&#40;step1, x&#41;
   z      &#61; parallel_step&#40;step2, y&#41;
   output &#61; parallel_step&#40;step3, z&#41;
   
   return output
end

x_small  &#61; rand&#40;  1_000&#41;
x_large  &#61; rand&#40;100_000&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_small&#41;</code><br><pre><code class="plaintext code-output">  35.841 Î¼s (375 allocations: 61.523 KiB)
</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x_big&#41;</code><br><pre><code class="plaintext code-output">  104.260 Î¼s (375 allocations: 2.326 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>The examples illustrate the two-step process outlined. First, it shows that parallelization is advantageous only with large collections. Otherwise, the question of whether to parallelize shouldn&#39;t even arise. Second, once multithreading proves to be advantageous, it demonstrates that grouping all operations into a single task is faster than parallelizing each operation individually.</p><h4>Implications</h4><p>The strategy of parallelizing code at the highest possible level has significant implications for program design. In particular, when the program will eventually be applied to multiple independent objects. It suggests a practical guideline: start with an implementation for a single object, without introducing parallelism. After thoroughly optimizing the single-case code, integrate parallel execution at the top level. The approach not only improves performance, but also simplifies the development by making debugging and testing more straightforward.</p><p>A common application of this strategy arises in scientific simulations. In those cases, independent executions of the same model are required. Thus, the most effective approach is to maintain a single-threaded implementation of the model, eventually launching multiple instances in parallel. This design ensures that each run remains efficient at the single-thread level, while taking advantage of full resource utilization.</p><p></p></div></div></div></section><section id="the_importance_of_work_distribution" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>The Importance of Work Distribution</h2><p></p><p>Multithreading performance is heavily influenced by how evenly the computational workload is distributed across iterations. The <code>@threads</code> macro spawns a task for every iteration, making it highly effective when each iteration requires roughly equal processing time. In contrast, scenarios with uneven computational effort are more challenging. In such cases, some threads may finish early and remain idle, while others continue processing heavier tasks. This imbalance undermines parallel efficiency, substantially diminishing the performance gains of multithreading.</p><p>To address this issue, we need greater control over how work is distributed among threads. This calls for the use of <code>@spawn</code>.</p><p>One strategy is to make each iteration a separate task. However, such approach is extremely inefficient if there&#39;s a large number of iterations: creating far more tasks than there are threads introduces substantial and unnecessary overhead. The following example illustrates this problem.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @threads for i in eachindex&#40;x&#41;
        output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  5.877 ms (125 allocations: 76.309 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @sync for i in eachindex&#40;x&#41;
        @spawn output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  11.095 s (60005888 allocations: 5.277 GiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>An alternative strategy, which lets users fine-tune the workload of each task, is to partition iterations into smaller subsets that can be processed in parallel. Before detailing the implementation, we&#39;ll first explore how to partition a collection along with its indices through the <code>ChunkSplitters</code> package.</p><h4>Partitioning Collections</h4><p>The package <code>ChunkSplitters</code> provides two functions for <a href="/julia_book/PAGES/09f_lazyOperations">lazy</a> partitioning: <code>chunks</code> and <code>index_chunks</code>. These functions support <code>n</code> and <code>size</code> as keyword arguments, depending on the type of partition desired. Specifically, <code>n</code> sets the number of subsets to create, with each subset sized to distribute elements evenly. In contrast, <code>size</code> specifies the number of elements to be contained in each subset. Since an even distribution across all subsets can&#39;t be guaranteed in all cases, the package adjusts the number of elements in one of the subsets if necessary.</p><p>Below, we apply these functions to a variable <code>x</code> that contains the 26 letters of the alphabet. Note that the outputs provided require the use of <code>collect</code>, since <code>chunks</code> and <code>index_chunks</code> are lazy.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Partition By Number of Chunks</button> <button class="tablink" data-id="">Partition By Size of Chunks</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; 5

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">5-element Vector{UnitRange{Int64}}:
 1:6
 7:11
 12:16
 17:21
 22:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">5-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b", "c", "d", "e", "f"]
 ["g", "h", "i", "j", "k"]
 ["l", "m", "n", "o", "p"]
 ["q", "r", "s", "t", "u"]
 ["v", "w", "x", "y", "z"]</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

chunk_length  &#61; 10

chunk_indices &#61; index_chunks&#40;x, size &#61; chunk_length&#41;
chunk_values  &#61; chunks&#40;x, size &#61; chunk_length&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">3-element Vector{UnitRange{Int64}}:
 1:10
 11:20
 21:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">3-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"]
 ["k", "l", "m", "n", "o", "p", "q", "r", "s", "t"]
 ["u", "v", "w", "x", "y", "z"]</code></pre></div></div></div></div></div><p></p></details></div><p>For multithreading, a relevant partition is a number of chunks proportional to the number of worker threads. The example below implements this, generating both chunk indices and chunk values. Since this partition will eventually be used with for-loops, we also show how to use <code>enumerate</code> to pair each chunk with the values or subindices of its corresponding subset.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Partition By Number of Threads</button> <button class="tablink" data-id="">Partition By Number of Threads - Enumerate</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; nthreads&#40;&#41;

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_indices&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{UnitRange{Int64}}:
 1:2
 3:4
 â‹®
 25:25
 26:26</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_values&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}:
 ["a", "b"]
 ["c", "d"]
 â‹®
 ["y"]
 ["z"]</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x             &#61; string.&#40;&#39;a&#39;:&#39;z&#39;&#41;            # all letters from &quot;a&quot; to &quot;z&quot;

nr_chunks     &#61; nthreads&#40;&#41;

chunk_indices &#61; index_chunks&#40;x, n &#61; nr_chunks&#41;
chunk_values  &#61; chunks&#40;x, n &#61; nr_chunks&#41;

chunk_iter1   &#61; enumerate&#40;chunk_indices&#41;    # pairs &#40;i_chunk, chunk_index&#41;
chunk_iter2   &#61; enumerate&#40;chunk_values&#41;     # pairs &#40;i_chunk, chunk_value&#41;</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_iter1&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{Tuple{Int64, UnitRange{Int64}}}:
 (1, 1:2)
 (2, 3:4)
 â‹®
 (23, 25:25)
 (24, 26:26)</code></pre></div><p></p><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>collect&#40;chunk_iter2&#41;</code><br><pre><code class="plaintext code-output">24-element Vector{Tuple{Int64, SubArray{String, 1, Vector{String}, Tuple{UnitRange{Int64}}, true}}}:
 (1, ["a", "b"])
 (2, ["c", "d"])
 â‹®
 (23, ["y"])
 (24, ["z"])</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><section id="work_distribution_defining_tasks_through_chunks" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Work Distribution: Defining Tasks Through Chunks</h2><p></p><p>Leveraging the <code>ChunkSplitters</code> package together with <code>@spawn</code>, we can control how a for-loop is parallelized. The process divides iterations into chunks, where each of them correspond to an independent task to be processed concurrently.</p><p>Below, we show how to replicate the behavior of <code>@threads</code> via <code>@spawn</code>. The two approaches become equivalent when the number of chunks is set equal to the number of worker threads.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button> <button class="tablink" data-id="">@spawn (equivalent)</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; similar&#40;x&#41;
    
    @threads for i in eachindex&#40;x&#41;
        output&#91;i&#93; &#61; log&#40;x&#91;i&#93;&#41;
    end
    
    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  5.877 ms (125 allocations: 76.309 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.829 ms (157 allocations: 76.311 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;
    task_indices &#61; Vector&#123;Task&#125;&#40;undef, nr_chunks&#41;

    for &#40;i, chunk&#41; in enumerate&#40;chunk_ranges&#41;
        task_indices&#91;i&#93; &#61; @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return wait.&#40;task_indices&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.841 ms (151 allocations: 76.310 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>The flexibility of <code>@spawn</code> implies we&#39;re not constrained to following the approach of <code>@threads</code>. For instance, it&#39;s common to adopt a partitioning strategy where the number of chunks is proportional to the number of worker threads. This is shown below.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">@spawn</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn &#40;@views @. output&#91;chunk&#93; &#61; log&#40;x&#91;chunk&#93;&#41;&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 1 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  7.058 ms (157 allocations: 76.311 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 2 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  5.492 ms (302 allocations: 76.325 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 4 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.982 ms (590 allocations: 76.352 MiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function compute&#33;&#40;output, x, chunk&#41;
     @turbo for j in chunk 
        output&#91;j&#93; &#61; log&#40;x&#91;j&#93;&#41;
     end
end

function foo&#40;x, nr_chunks&#41;
    chunk_ranges &#61; index_chunks&#40;x, n&#61;nr_chunks&#41;
    output       &#61; similar&#40;x&#41;

    @sync for chunk in chunk_ranges
        @spawn compute&#33;&#40;output, x, chunk&#41;
    end

    return output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 1 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.379 ms (133 allocations: 76.310 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 2 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.529 ms (254 allocations: 76.323 MiB)
</code></pre></div><p></p><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x, 4 * nthreads&#40;&#41;&#41;</code><br><pre><code class="plaintext code-output">  4.080 ms (494 allocations: 76.347 MiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>Having more chunks than number of threads can make sense when, for instance, the processor&#39;s cores don&#39;t offer uniform performance. When this is the case, the strategy will ensure that there the fastest cores don&#39;t remain idle, so that there&#39;s full resource utilization of computational resources.</p><p></p></div></div></div></section><section id="handling_dependencies" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Handling Dependencies</h2><p></p><p>So far, our discussion of parallelization has focused on embarrassingly parallel for-loops, where iterations are completely independent. This enables the execution of each iteration in isolation, making parallelization straightforward.</p><p>The situation becomes more complex when operations exhibit dependencies. Attempting to parallelize without first addressing these dependencies can lead not only to inefficiencies and wasted resources, but most critically to incorrect results.</p><p>There&#39;s no one-size-fits-all method for handling dependencies. The appropriate strategy depends on the structure of the specific program. In all cases, though, the approach will require adapting the parallelization technique to work on a reformulated version of the problem. This reformulation must ensure that the tasks to be parallelized are independentâ€”ultimately, parallelization is only possible if independence between operations can be achieved.</p><p>Note that, once dependencies are present, some portion of the work will inevitably be non-parallelizable. In fact, no subset of independent tasks may exist at all, as when computations are inherently sequential.</p><p></p></div></div></div></section><section id="handling_reductions" class="scrollspy section-bg-color"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>Handling Reductions</h2><p></p><p>A common technique that exhibits dependency between iterations is reductions. To still benefit from parallelization despite this dependency, its computation must be reorganized. The typical strategy is to partition the data into chunks, perform a partial reduction on each chunk in parallel, and then combine the partial results in a final reduction step. This restructuring removes the original dependency between iterations, since each partial reduction now operates on a disjoint subset of the data.</p><p>To illustrate, let&#39;s compute the sum of elements of a vector <code>x</code>. The implementation relies on the <code>ChunkSplitters</code> package to divide the data into independent segments.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Julia's Default (Sequential)</button> <button class="tablink" data-id="">@threads</button> <button class="tablink" data-id="">@spawn</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; 0.0

    for i in eachindex&#40;x&#41;
        output &#43;&#61; x&#91;i&#93;
    end

    output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  5.203 ms (0 allocations: 0 bytes)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        partial_outputs&#91;i&#93; &#61; sum&#40;@view&#40;x&#91;chunk&#93;&#41;&#41;
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  1.268 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
         
    @sync for &#40;i, chunk&#41; in enumerate&#40;chunk_ranges&#41;
        @spawn partial_outputs&#91;i&#93; &#61; sum&#40;@view&#40;x&#91;chunk&#93;&#41;&#41;
    end
        
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  1.286 ms (156 allocations: 13.781 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><section id="false_sharing" class="scrollspy"><div class="container"><div class="row"><div class="col-lg- mx-auto"><h2>False Sharing</h2><p></p><p>Addressing dependency between operations is necessary when parallelizing, since the program may otherwise yield incorrect results. However, even after removing dependencies and ensuring correctness, performance can still suffer due to hardware-level effects.</p><p>One common bottleneck is <strong>cache contention</strong>, where multiple processor cores compete for shared cache resources. A manifestation of this issue is what&#39;s known as <span style="color:#3e79b4"><strong>false sharing</strong></span>, where multiple cores simultaneously access data stored in the same cache line. To understand why this degrades performance, it helps to first review how CPU caches work.</p><p>Processors rely on caches to hold copies of frequently accessed data. These caches are much smaller but significantly faster than main memory &#40;RAM&#41;, and they&#39;re organized into fixed-size blocks called cache lines &#40;typically 64 bytes&#41;. When the processor needs a piece of data, it first checks whether it&#39;s already present in the cache. If not, the data must be fetched from RAM and placed into a cache line, a process that&#39;s considerably slower.</p><p>Likewise, when multiple cores access data within the same cache line, the transfer of information is governed by a cache coherency protocol. Its goal is to ensure consistency across cores. However, the protocol can create inefficiencies: even if one core accesses data that remains unmodified, any modification to another value within the same cache line may cause the entire line to be invalidated. As a result, all cores are forced to reload the block, despite the absence of a logical need to do so. This phenomenon, known as <strong>false sharing</strong>, leads to unnecessary cache invalidations and refetches. The outcome is a notable degradation in program performance, particularly in workloads where threads frequently update their variables.</p><p></p><div class="multiple_pics"><img src="/julia_book/assets/PAGES/11f_multithread_apply/tikz/false_sharing.svg" style="width:500px;height:auto;margin-top:1em;max-width:100%"></div><br><p></p><p>Below, we focus on the emergence of false sharing in reduction operations.</p><h4>False Sharing In Reductions: An Illustration and Solutions</h4><p>Suppose that the elements of a vector are summed after applying a logarithmic transformation. We&#39;ll present two implementations. The first one acts as a baseline and consists of a sequential procedure. The second one is multithreaded but suffers from false sharing. The problem arises because each thread writes its partial sum into a different element of the <code>partial_outputs</code> vector. Although these elements are logically independent, they&#39;re stored in adjacent memory locations that fall within the same cache line. As a result, every update by one thread invalidates the cache line in other cores, forcing unnecessary reloads that degrade performance.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Sequential</button> <button class="tablink" data-id="">False Sharing</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    output &#61; 0.0

    for i in eachindex&#40;x&#41;
        output &#43;&#61; log&#40;x&#91;i&#93;&#41;
    end

    output
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  37.046 ms (0 allocations: 0 bytes)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        for j in chunk
            partial_outputs&#91;i&#93; &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  17.434 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>There are several strategies to address the issue. All of them ensure that threads don&#39;t write to data residing in the same cache line.</p><p>One common strategy is <strong>vector padding</strong>, where extra spacing is inserted between the elements of <code>partial_outputs</code>. This strategy ensures that each thread&#39;s accumulator is placed on a distinct cache line, so that concurrent writes no longer interfere with one another at the cache level. We implement this below by storing the partial outputs in a vector with sufficient separation between rows. In particular, a separation of 8 entries.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Padding</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    nr_strides      &#61; 8
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41; * nr_strides&#41;

    @threads for &#40;i, chunk&#41; in enumerate&#40;chunk_ranges&#41;
        for j in chunk
            partial_outputs&#91;&#40;i-1&#41;*nr_strides &#43; 1&#93; &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
    end

    return sum&#40;@view&#40;partial_outputs&#91;1:nr_strides:end&#93;&#41;&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  6.243 ms (124 allocations: 14.625 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p>While intuitive, the solution lacks practical appeal. In fact, the exact number of rows to insert depends on the element type and the underlying computer architecture. For this reason, let&#39;s introduce more efficient general approaches to avoiding false sharing.</p><p>The first method introduces a thread-local variable <code>temp</code> to store partial results. In this way, each thread updates only its own local variable, finally writing to the shared array exactly once at the end. We implement this solution via <code>@threads</code> and <code>@spawn</code>. After that, we present an alternative solution where each partial reduction is computed inside a separate function. This addresses false sharing in a similar spirit, where accumulation is based on a local variable.</p><div class="hide_tab"><details open><summary><div class="closed_text"></div></summary><p></p><div class="tab_wrapper"><div class="tab_code_links"><button class="tablink first_tab active" data-id="">Local Variable (@threads)</button> <button class="tablink" data-id="">Local Variable (@spawn)</button> <button class="tablink" data-id="">Function</button></div><div data-id="" class="tabcontent active"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        temp &#61; 0.0
        for j in chunk
            temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
        end
        partial_outputs&#91;i&#93; &#61; temp
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  4.820 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;    
    
    @sync for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        @spawn begin
            temp &#61; 0.0
            for j in chunk
                temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
            end
            partial_outputs&#91;i&#93; &#61; temp
        end
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  4.385 ms (156 allocations: 13.781 KiB)
</code></pre></div></div></div></div><div data-id="" class="tabcontent"><div class="code_in_modal"><div class="code_NoFormat"><pre><code class="language-julia">x &#61; rand&#40;10_000_000&#41;

function compute&#40;x, chunk&#41;
    temp &#61; 0.0

    for j in chunk
        temp &#43;&#61; log&#40;x&#91;j&#93;&#41;
    end
    
    return temp
end

function foo&#40;x&#41;
    chunk_ranges    &#61; index_chunks&#40;x, n&#61;nthreads&#40;&#41;&#41;
    partial_outputs &#61; Vector&#123;Float64&#125;&#40;undef, length&#40;chunk_ranges&#41;&#41;    
    
    @threads for &#40;i,chunk&#41; in enumerate&#40;chunk_ranges&#41;
        partial_outputs&#91;i&#93; &#61; compute&#40;x, chunk&#41;
    end
    
    return sum&#40;partial_outputs&#41;
end</code></pre></div></div><div class="output_in_modal"><div class="sign_output">Output in REPL</div><div class="mixed_output_inline"><div class="mixed_output_NoFormat"><div class="julia_line">julia&gt</div><code>@btime foo&#40;&#36;x&#41;</code><br><pre><code class="plaintext code-output">  4.851 ms (124 allocations: 13.250 KiB)
</code></pre></div></div></div></div></div><p></p></details></div><p></p></div></div></div></section><footer class="py-1"><div class="container"><span class="left-text"><a href="/julia_book/PAGES/11e_multithread_loops" class="prevPage"><img src="/julia_book/assets/icons/prev-page.png" style="width:50px;height:auto;opacity:.9;padding-bottom:5px"> Previous Section <span class="ctrl-text">( <kbd>Ctrl + <img src="/julia_book/assets/icons/arrow_left.png" style="width:15px;height:auto;opacity:.9;padding-bottom:2px"> </kbd>)</span> </a></span><span class="right-text"><a href="/julia_book/PAGES/11g_multithread_packages" class="nextPage">Next Section <span class="ctrl-text">( <kbd>Ctrl + <img src="/julia_book/assets/icons/arrow_right.png" style="width:15px;height:auto;opacity:.9;padding-bottom:2px"> </kbd>)</span> <img src="/julia_book/assets/icons/next-page.png" style="width:50px;height:auto;opacity:.9;padding-bottom:5px"> </a></span><span class="center-text">Â© Martin Alfaro<br>Last Modified January 27, 2026</span></div></footer><style>@media (max-width:850px),(max-height:600px){.ctrl-text{display:none}}footer{font-family:Inter}footer .container{width:100%;margin-top:.6em;margin-bottom:.5em;overflow:hidden;text-align:center;align-items:center;justify-content:center;color:#fff}footer .center-text{text-align:center}footer .left-text{float:left}footer .right-text{float:right}footer a{color:#fff}footer a:hover{color:#fff;opacity:.9;text-decoration:none}</style><script>const prevPageURL=document.querySelector(".prevPage").href,nextPageURL=document.querySelector(".nextPage").href;function goToPrevPage(){window.location=prevPageURL}function goToNextPage(){window.location=nextPageURL}document.querySelector(".prevPage").addEventListener("click",goToPrevPage),document.querySelector(".nextPage").addEventListener("click",goToNextPage),document.addEventListener("keyup",e=>{"ArrowLeft"===e.key&&e.ctrlKey?goToPrevPage():"ArrowRight"===e.key&&e.ctrlKey&&goToNextPage()})</script></div><script src="/julia_book/libs/katex/katex.min.js"></script><script src="/julia_book/libs/katex/auto-render.min.js"></script><script>renderMathInElement(document.body)</script><script src="/julia_book/libs/highlight/highlight.js"></script><script>hljs.highlightAll(),hljs.configure({tabReplace:"    "})</script><script src="/julia_book/libs/simple-scrollspy.min.js"></script><script>window.onload=function(){scrollSpy("#navbarResponsive",{sectionClass:".scrollspy",menuActiveTarget:".nav-link",offset:100})}</script></body></html><!-- 
#################################################
# FOR ALL PAGES
################################################# 
--><script>const btns=document.getElementsByClassName("modalButton"),modals=document.getElementsByClassName("modal");[...btns].forEach((e,t)=>{e.onclick=()=>{"block"===modals[t].style.display?modals[t].style.display="none":modals[t].style.display="block"}}),window.addEventListener("click",function(e){const t=document.getElementsByClassName("modal"),l=document.getElementsByClassName("modal-content"),n=document.getElementsByClassName("modalButton");for(let s=0;s<t.length;s++){const o=t[s],a=l[s],d=n[s];"block"!==o.style.display||a.contains(e.target)||d.contains(e.target)||(o.style.display="none")}}),document.addEventListener("keydown",function(e){if(e.ctrlKey&&"z"===e.key){const e=document.getElementById("modal_bar");e&&"block"===e.style.display?e.style.display="none":e.style.display="block"}})</script><script>let handleClick=e=>{Array.from(e.target.parentElement.parentElement.querySelectorAll(".active"),e=>e.classList.remove("active")),e.target.classList.add("active"),document.querySelector(`div.tabcontent[data-id*="${e.target.dataset.id}"]`).classList.add("active")};Array.from(document.getElementsByClassName("tablink"),e=>e.addEventListener("click",handleClick,!1))</script><script>let setHeight=()=>{document.querySelectorAll(".tab_wrapper").forEach(e=>{let t=e.querySelectorAll(".tabcontent"),i=0,l=0;t.forEach(e=>{let t=e.style.visibility;e.style.visibility="visible";let o=e.style.position,s=e.style.display;e.style.position="relative",e.style.display="inline-block";let y=e.querySelector(".code_in_modal"),r=e.querySelector(".output_in_modal");if(y){y.style.height="auto";let e=y.offsetHeight;e>i&&(i=e)}if(r){r.style.height="auto";let e=r.offsetHeight;e>l&&(l=e)}e.style.visibility=t,e.style.position=o,e.style.display=s}),t.forEach(e=>{let t=e.querySelector(".code_in_modal"),o=e.querySelector(".output_in_modal");t&&(t.style.height=i+"px"),o&&(o.style.height=l+"px")})})};window.addEventListener("load",setHeight),window.addEventListener("resize",setHeight)</script><script>for(var tabWrappers=document.getElementsByClassName("tab_wrapper"),i=0;i<tabWrappers.length;i++)for(var tabWrapper=tabWrappers[i],buttons=tabWrapper.getElementsByClassName("tablink"),tabContents=tabWrapper.getElementsByClassName("tabcontent"),j=0;j<buttons.length;j++){var button=buttons[j],tabContent=tabContents[j],dataId="tab"+(i+1)+"_"+(j+1);button.setAttribute("data-id",dataId),tabContent.setAttribute("data-id",dataId)}</script><script>document.addEventListener("keydown",function(e){if("ArrowUp"===e.code&&e.altKey)for(var n=document.getElementsByTagName("details"),t=0;t<n.length;t++)n[t].open=!1})</script><script>document.addEventListener("keydown",function(e){if("ArrowDown"===e.code&&e.altKey)for(var n=document.getElementsByTagName("details"),o=0;o<n.length;o++)n[o].open=!0}),window.onkeydown=function(e){if("Escape"==e.key)for(let e of modals)e.style.display="none"}</script><style>.pic_drop_green{padding-top:1em;padding-bottom:1em}.pic_drop_green details>summary{color:#fff;display:inline-block;width:auto;cursor:pointer;padding:0 6px;margin:0;border-width:1px;border-style:solid;box-shadow:3px 3px 4px #000;background-color:#3f6b4b}.pic_drop_green details[open]>summary{width:auto;padding:0 6px;border:#a8a8a8;border-width:1px;border-style:solid;color:#fff;background-color:#3f6b4b}.pic_drop_green details>p{display:block;width:auto;padding:0;margin:0}.multiple_pics{text-align:center}.multiple_pics h2{text-decoration:none;padding-bottom:0}.multiple_pics .row{display:flex}.multiple_pics .column2{flex:50%}.multiple_pics .column3{flex:33.33%}</style><style>#search_modal_container .pagefind-ui__message,#search_modal_container .pagefind-ui__result-title,#search_modal_container p{display:block;width:100%!important;white-space:normal;text-indent:0}#search_modal_container .pagefind-ui__search-clear{font-size:100%}.bar_top .searchBar{display:flex;justify-content:center;width:auto}.bar_top .searchBar .modal-header{background-color:#3f6388}.bar_top .searchBar .modal-content{position:relative;width:auto;max-width:70%;height:max-content;max-height:90%;background-color:#cdd6e0;margin:auto;margin-left:160px;padding:8px;-webkit-animation-name:none;animation-name:none}.bar_top .searchBar .modal-body{padding:10px}#search_modal_container .pagefind-ui__result{margin:4px 0;padding:6px 8px}html.dark-mode #searchLine,html.dark-mode #search_modal_container{--pagefind-ui-text:rgb(235, 244, 252);--pagefind-ui-background:rgb(3, 9, 17);--pagefind-ui-placeholder:rgb(235, 244, 252);--pagefind-ui-border-radius:0px}html.dark-mode #searchLine ::placeholder,html.dark-mode #search_modal_container ::placeholder{opacity:.5}html.dark-mode #search_modal_container .pagefind-ui__button{color:rgba(235,244,252,.6)}#search_modal_container{--pagefind-ui-scale:0.9}#search_modal_container .pagefind-ui__search-clear{display:none}#search_modal_container .pagefind-ui__button{padding:0;height:auto}</style><script>let pagefind;window.addEventListener("DOMContentLoaded",()=>{pagefind=new PagefindUI({element:"#search_modal_container"})}),document.getElementById("openSearch").addEventListener("click",()=>{document.getElementById("searchModal").style.display="block",setTimeout(()=>{const e=document.querySelector("#search_modal_container input");e&&e.focus()},100)})</script><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector("#search_modal_container");let t=-1;e.addEventListener("keydown",n=>{const r=e.querySelectorAll(".pagefind-ui__result a");r.length&&("ArrowDown"===n.key&&(n.preventDefault(),t=(t+1)%r.length,r[t].focus()),"ArrowUp"===n.key&&(n.preventDefault(),t=(t-1+r.length)%r.length,r[t].focus()),"Enter"===n.key&&t>=0&&(n.preventDefault(),r[t].click()))});new MutationObserver(()=>{t=-1}).observe(e,{childList:!0,subtree:!0})})</script><script>function generateId(e){return e.toLowerCase().replace(/[^\w\s]/g,"").replace(/\s+/g,"_")}function copyToClipboard(e){const t=document.createElement("input");document.body.appendChild(t),t.value=e,t.select(),document.execCommand("copy"),document.body.removeChild(t)}function showTooltip(e,t,n="Link Copied"){const o=document.createElement("div");o.style.position="absolute";const l=document.createElement("span");l.textContent=n,l.style.position="absolute",l.style.background="rgba(63, 99, 136, 0.75)",l.style.color="white",l.style.padding="4px 2px",l.style.borderRadius="4px",l.style.fontSize="14px",l.style.textAlign="center",l.style.fontWeight="700",o.appendChild(l),t.appendChild(o);const i=t.getBoundingClientRect(),c=e.clientX-i.left-28,d=e.clientY-i.bottom-25;l.style.top=`${d}px`,l.style.left=`${c}px`,setTimeout(()=>{t.removeChild(o)},1e3)}function handleH2Elements(){document.querySelectorAll("h2").forEach(e=>{e.addEventListener("click",function(t){const n=e.textContent.trim();copyToClipboard(`${window.location.origin}${window.location.pathname}#${generateId(n)}`),showTooltip(t,e)})})}function handleH4Elements(){document.querySelectorAll("h4").forEach(e=>{const t=`sub_${generateId(e.textContent.trim())}`;e.setAttribute("id",t);const n=document.createElement("a");n.href=`#${t}`,n.innerHTML=e.innerHTML,n.style.textDecoration="underline",e.innerHTML="",e.appendChild(n),n.addEventListener("click",function(t){copyToClipboard(n.href),showTooltip(t,e),t.preventDefault()})})}document.addEventListener("DOMContentLoaded",function(){handleH2Elements(),handleH4Elements()})</script><style>h2,h4{cursor:pointer}.hand-cursor{cursor:wait}h2:hover,h4:hover{color:rgba(0,0,0,.5)}</style><!-- 
#################################################
# FOR EACH SPECIFIC PAGE
#################################################
 --><nav class="nav"><button class="nav-toggle" aria-label="Toggle navigation"><img src="/julia_book/assets/icons/dropdown.png" style="width:auto;height:30px;opacity:.9;padding-bottom:2px;margin-left:0"> <span class="nav-title"><i>11f.</i> Parallelization in Practice</span></button><div class="nav-menu"><ul><li><a href="#introduction" data-offset="-40">Introduction</a></li><li><a href="#better_to_parallelize_at_the_top" data-offset="-40">Better To Parallelize at The Top</a></li><li><a href="#the_importance_of_work_distribution" data-offset="-40">The Importance of Work Distribution</a></li><li><a href="#work_distribution_defining_tasks_through_chunks" data-offset="-40">Work Distribution: Defining Tasks Through Chunks</a></li><li><a href="#handling_dependencies" data-offset="-40">Handling Dependencies</a></li><li><a href="#handling_reductions" data-offset="-40">Handling Reductions</a></li><li><a href="#false_sharing" data-offset="-40">False Sharing</a></li></ul></div></nav><script>const navToggle=document.querySelector(".nav-toggle"),navMenu=document.querySelector(".nav-menu"),navLinks=document.querySelectorAll(".nav-menu a");navToggle.addEventListener("click",()=>{navMenu.classList.toggle("show")}),navLinks.forEach(e=>{e.addEventListener("click",n=>{n.preventDefault();const t=document.querySelector(e.getAttribute("href")),o=parseInt(e.dataset.offset,10)||0;window.scrollTo({top:t.offsetTop+o,behavior:"smooth"})})}),document.addEventListener("click",e=>{navMenu.contains(e.target)||navToggle.contains(e.target)||navMenu.classList.remove("show")}),document.addEventListener("keydown",e=>{"Escape"===e.key&&navMenu.classList.remove("show"),"x"===e.key&&e.ctrlKey&&navMenu.classList.toggle("show")})</script><style>.nav{position:fixed;top:0;right:0;z-index:200;background-color:#3f6388;padding:0;display:block;font-family:Inter}.nav-toggle{background-color:#3f6388;border:none;padding:8px;padding-right:24px;font-size:18px;cursor:pointer}.nav-menu{position:fixed;right:0;top:48px;background-color:#3f6388;padding:10px;width:300px;height:100vh;overflow-y:auto;display:none}.nav-menu ul{list-style:none;margin:0;padding:0}.nav-menu li{margin-bottom:10px}.nav-menu a{color:#fff;text-decoration:none;font-size:18px;font-weight:700;text-align:center;padding:10px 10px;display:block}.nav-menu a:hover{color:#fff;background-color:#000}.nav-title{font-size:18px;margin-left:10px;color:#fff}.nav-brand{font-size:24px;font-weight:700;margin:10px 20px;color:#fff}.nav-menu.show{display:block}</style><script src="/julia_book/libs/clipboard.min.js"></script><script>!function(){for(var t=document.getElementsByTagName("pre"),e=0;e<t.length;e++){var n=t[e].children[0].className;if(n.startsWith("language-")||n.endsWith(" hljs")){var o=document.createElement("button");o.className="copy-button",o.textContent="Copy",t[e].appendChild(o)}}var r=new Clipboard(".copy-button",{target:function(t){return t.previousElementSibling}});r.on("success",function(t){t.clearSelection(),t.trigger.textContent="copied!",window.setTimeout(function(){t.trigger.textContent="copy"},2e3)}),r.on("error",function(t){t.trigger.textContent='Press "Ctrl + C" to copy',window.setTimeout(function(){t.trigger.textContent="Copy"},5e3)})}()</script><style>@media print{.franklin-content{box-sizing:border-box}.jumbotron{padding-right:60px!important}.jumbotron,.name_format,.phd_format{color:#000!important}.name_format a{color:#3f6388}.hide_tab details[open] p,.hide_tab>details[open]>summary,.sign_output,.tab_code_links,nav{display:none!important}.bar_top,.bar_top .modalButton,.copy-button,.footn,.left_bar,.left_bar_mobile,.nav-item,.navbar,footer,nav{display:none!important}.tab_wrapper{display:flex!important;flex-wrap:wrap;gap:1cm;width:100%;padding-top:20px;padding-bottom:20px}.tabcontent{display:block!important;margin-bottom:2em;page-break-inside:avoid;border:2px solid #3f6388!important}.print-tab-title{font-weight:700;font-size:100%;padding:0 0;padding-left:.35cm;color:#000;text-transform:uppercase;display:block!important}.code_in_modal,.output_in_modal{width:100%;height:auto!important;overflow:visible;border:none!important}.code_NoFormat pre,.mixed_output_NoFormat pre{border:none!important}.code_NoFormat,.code_in_modal,.julia_repl_NoFormat,.mixed_output_NoFormat,.mixed_output_inline{margin:0!important;padding:0!important}.code_NoFormat,.julia_repl_NoFormat,.mixed_output_NoFormat{padding-left:.35cm!important;padding-top:.15cm!important}.output_in_modal{margin-top:12px!important;border-top:2px solid #20c679!important}.code_NoFormat,.code_in_modal{border-top:2px solid #3f6388}#remarkCodeContent{height:.1px!important;visibility:hidden!important}}</style><script>function printAllTabs(){const t=document.querySelectorAll(".tablink");document.querySelectorAll(".tabcontent").forEach((e,n)=>{const r=t[n].textContent.trim();if(!e.querySelector(".print-tab-title")){const t=document.createElement("div");t.className="print-tab-title",t.textContent=r,e.insertBefore(t,e.firstChild)}});for(var e=document.getElementsByTagName("a"),n=0;n<e.length;n++)e[n].removeAttribute("href"),e[n].style.textDecoration="none"}window.matchMedia("print").addListener(t=>{if(t.matches)printAllTabs();else{document.querySelectorAll(".tabcontent").forEach(t=>{const e=t.querySelector(".print-tab-title");e&&t.removeChild(e)})}})</script>